{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 지도학습 기반 감성분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 감성분석은 문서 내 텍스트가 나타내는 여러 가지 주관적인 단어와 문맥을 기반으로 감성 수치를 계산하는 방법을 이용\n",
    "- 감성 지수는 긍정 감성 지수와 부정 감성 지수로 구성되며 이들 지수를 합산해 긍정 또는 부정 감성을 결정\n",
    "- 지도 학습은 학습 데이터와 타깃 레이블 값을 기반으로 감성 분석 학습을 수행한 뒤 이를 기반으로 다른 데이터의 감성 분석을 예측하는 방법\n",
    "- 비지도 학습은 'Lexicon'이라는 일종의 감성 어휘 사전을 이용. Lexicon의 감성 분석을 위한 용어와 문맥에 대한 다양한 정보를 이용해 문서의 긍정적 부정적 감성 여부를 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  sentiment                                             review\n",
      "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
      "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
      "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['id', 'sentiment', 'review'], dtype=object)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 지도학습 기반 - IMDB 영화평\n",
    "# https://www.kaggle.com/c/word2vec-nlp-tutorial/data\n",
    "\n",
    "import pandas as pd\n",
    "review_df = pd.read_csv('./dataset/labeledTrainData.tsv', header = 0, sep='\\t', quoting=3)\n",
    "print(review_df.head(3))\n",
    "review_df.shape\n",
    "review_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"It must be assumed that those who praised this film (\\\"the greatest filmed opera ever,\\\" didn't I read somewhere?) either don't care for opera, don't care for Wagner, or don't care about anything except their desire to appear Cultured. Either as a representation of Wagner's swan-song, or as a movie, this strikes me as an unmitigated disaster, with a leaden reading of the score matched to a tricksy, lugubrious realisation of the text.<br /><br />It's questionable that people with ideas as to what an opera (or, for that matter, a play, especially one by Shakespeare) is \\\"about\\\" should be allowed anywhere near a theatre or film studio; Syberberg, very fashionably, but without the smallest justification from Wagner's text, decided that Parsifal is \\\"about\\\" bisexual integration, so that the title character, in the latter stages, transmutes into a kind of beatnik babe, though one who continues to sing high tenor -- few if any of the actors in the film are the singers, and we get a double dose of Armin Jordan, the conductor, who is seen as the face (but not heard as the voice) of Amfortas, and also appears monstrously in double exposure as a kind of Batonzilla or Conductor Who Ate Monsalvat during the playing of the Good Friday music -- in which, by the way, the transcendant loveliness of nature is represented by a scattering of shopworn and flaccid crocuses stuck in ill-laid turf, an expedient which baffles me. In the theatre we sometimes have to piece out such imperfections with our thoughts, but I can't think why Syberberg couldn't splice in, for Parsifal and Gurnemanz, mountain pasture as lush as was provided for Julie Andrews in Sound of Music...<br /><br />The sound is hard to endure, the high voices and the trumpets in particular possessing an aural glare that adds another sort of fatigue to our impatience with the uninspired conducting and paralytic unfolding of the ritual. Someone in another review mentioned the 1951 Bayreuth recording, and Knappertsbusch, though his tempi are often very slow, had what Jordan altogether lacks, a sense of pulse, a feeling for the ebb and flow of the music -- and, after half a century, the orchestral sound in that set, in modern pressings, is still superior to this film.\"\n"
     ]
    }
   ],
   "source": [
    "print(review_df.review[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fruit box fruit tree'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re.sub 사용법\n",
    "import re\n",
    "# 사과 혹은 오렌지를 과일로 대체\n",
    "re.sub('apple|orange', 'fruit', 'apple box orange tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' It must be assumed that those who praised this film    the greatest filmed opera ever    didn t I read somewhere   either don t care for opera  don t care for Wagner  or don t care about anything except their desire to appear Cultured  Either as a representation of Wagner s swan song  or as a movie  this strikes me as an unmitigated disaster  with a leaden reading of the score matched to a tricksy  lugubrious realisation of the text   It s questionable that people with ideas as to what an opera  or  for that matter  a play  especially one by Shakespeare  is   about   should be allowed anywhere near a theatre or film studio  Syberberg  very fashionably  but without the smallest justification from Wagner s text  decided that Parsifal is   about   bisexual integration  so that the title character  in the latter stages  transmutes into a kind of beatnik babe  though one who continues to sing high tenor    few if any of the actors in the film are the singers  and we get a double dose of Armin Jordan  the conductor  who is seen as the face  but not heard as the voice  of Amfortas  and also appears monstrously in double exposure as a kind of Batonzilla or Conductor Who Ate Monsalvat during the playing of the Good Friday music    in which  by the way  the transcendant loveliness of nature is represented by a scattering of shopworn and flaccid crocuses stuck in ill laid turf  an expedient which baffles me  In the theatre we sometimes have to piece out such imperfections with our thoughts  but I can t think why Syberberg couldn t splice in  for Parsifal and Gurnemanz  mountain pasture as lush as was provided for Julie Andrews in Sound of Music     The sound is hard to endure  the high voices and the trumpets in particular possessing an aural glare that adds another sort of fatigue to our impatience with the uninspired conducting and paralytic unfolding of the ritual  Someone in another review mentioned the      Bayreuth recording  and Knappertsbusch  though his tempi are often very slow  had what Jordan altogether lacks  a sense of pulse  a feeling for the ebb and flow of the music    and  after half a century  the orchestral sound in that set  in modern pressings  is still superior to this film  '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df/series 에서 str 적용 문자열 연산 수행\n",
    "import re\n",
    "# <br> html 태그는 replace 함수로 공백으로 변환\n",
    "review_df.review = review_df.review.str.replace('<br />', ' ')\n",
    "# 파이썬의 정규 표현식 모듈 re를 이용하여 영어 문자열이 아닌 문자는 모두 공백으로 변환\n",
    "# 알파벳이 아닌 것 모두 공백으로 변환\n",
    "review_df.review = review_df.review.apply(lambda x : re.sub('[^a-zA-Z]', ' ', x))\n",
    "review_df.review[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17500, 1), (7500, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "class_df = review_df.sentiment\n",
    "feature_df = review_df.drop(['id', 'sentiment'], axis = 1, inplace = False)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    feature_df\n",
    "    , class_df\n",
    "    , test_size=0.3\n",
    "    , random_state=156\n",
    ")\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score , recall_score , confusion_matrix, f1_score, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test , pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "  \n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}'.format(accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 : 0.8865, ROC-AUC : 0.9508\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# 스톱 워드는 English, filtering, ngram은 (1,2)로 설정해 CountVectorization수행. \n",
    "# LogisticRegression의 C는 10으로 설정.\n",
    "# 파이프라인을 이용하여 한번에 수행(명령 한꺼번에)\n",
    "pipeline = Pipeline([\n",
    "    ('cnt_vect', CountVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "    ('lr_clf', LogisticRegression(C=10))])\n",
    "# Pipeline 객체를 이용하여 fit(), predict()로 학습/예측 수행. predict_proba()는 \n",
    "# roc_auc때문에 수행.\n",
    "\n",
    "# 학습\n",
    "pipeline.fit(x_train.review, y_train)\n",
    "\n",
    "# 예측\n",
    "pred = pipeline.predict(x_test.review)\n",
    "\n",
    "# ROC-AUC 때문에 predict_proba 필요\n",
    "pred_probs = pipeline.predict_proba(x_test.review)[:,1]\n",
    "\n",
    "print('예측 정확도 : {0:.4f}, ROC-AUC : {1:.4f}'.format(accuracy_score(y_test,pred), roc_auc_score(y_test,pred_probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[3257  423]\n",
      " [ 376 3444]]\n",
      "정확도: 0.8935, 정밀도: 0.8906, 재현율: 0.9016,    F1: 0.8961\n",
      "\n",
      "ROC-AUC:  0.9597786962212611\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "    ('lr_clf', LogisticRegression(C=10))])\n",
    "# Pipeline 객체를 이용하여 fit(), predict()로 학습/예측 수행. predict_proba()는 \n",
    "# roc_auc때문에 수행.\n",
    "\n",
    "# 학습\n",
    "pipeline.fit(x_train.review, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = pipeline.predict(x_test.review)\n",
    "\n",
    "# ROC-AUC 때문에 predict_proba 필요\n",
    "pred_probs = pipeline.predict_proba(x_test.review)[:,1]\n",
    "\n",
    "get_clf_eval(y_test, y_pred)\n",
    "print()\n",
    "print('ROC-AUC: ', roc_auc_score(y_test, pred_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 비지도학습 기반 감성 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sysnsets() 반환 type:  <class 'list'>\n",
      "sysnsets() 반환 값 개수:  18\n",
      "sysnsets() 반환 값:  [Synset('present.n.01'), Synset('present.n.02'), Synset('present.n.03'), Synset('show.v.01'), Synset('present.v.02'), Synset('stage.v.01'), Synset('present.v.04'), Synset('present.v.05'), Synset('award.v.01'), Synset('give.v.08'), Synset('deliver.v.01'), Synset('introduce.v.01'), Synset('portray.v.04'), Synset('confront.v.03'), Synset('present.v.12'), Synset('salute.v.06'), Synset('present.a.01'), Synset('present.a.02')]\n"
     ]
    }
   ],
   "source": [
    "# 'present' 라는 단어로 wordnet의 sysnset 생성\n",
    "# synsets 호출 시 Synset 객체를 가지는 list를 반환\n",
    "# POS(Part of speech) 태그는 의미, 품사, 인덱스로 구성\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "term = 'present'\n",
    "synsets = wn.synsets(term)\n",
    "print('sysnsets() 반환 type: ', type(synsets))\n",
    "print('sysnsets() 반환 값 개수: ', len(synsets))\n",
    "print('sysnsets() 반환 값: ', synsets)\n",
    "# 단어 하나의 경우의 수 파악하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Synset name:  present.n.01  #####\n",
      "POS : noun.time\n",
      "Definition : the period of time that is happening now; any continuous stretch of time including the moment of speech\n",
      "Lemmas:  ['present', 'nowadays']\n",
      "##### Synset name:  present.n.02  #####\n",
      "POS : noun.possession\n",
      "Definition : something presented as a gift\n",
      "Lemmas:  ['present']\n",
      "##### Synset name:  present.n.03  #####\n",
      "POS : noun.communication\n",
      "Definition : a verb tense that expresses actions or states at the time of speaking\n",
      "Lemmas:  ['present', 'present_tense']\n",
      "##### Synset name:  show.v.01  #####\n",
      "POS : verb.perception\n",
      "Definition : give an exhibition of to an interested audience\n",
      "Lemmas:  ['show', 'demo', 'exhibit', 'present', 'demonstrate']\n",
      "##### Synset name:  present.v.02  #####\n",
      "POS : verb.communication\n",
      "Definition : bring forward and present to the mind\n",
      "Lemmas:  ['present', 'represent', 'lay_out']\n",
      "##### Synset name:  stage.v.01  #####\n",
      "POS : verb.creation\n",
      "Definition : perform (a play), especially on a stage\n",
      "Lemmas:  ['stage', 'present', 'represent']\n",
      "##### Synset name:  present.v.04  #####\n",
      "POS : verb.possession\n",
      "Definition : hand over formally\n",
      "Lemmas:  ['present', 'submit']\n",
      "##### Synset name:  present.v.05  #####\n",
      "POS : verb.stative\n",
      "Definition : introduce\n",
      "Lemmas:  ['present', 'pose']\n",
      "##### Synset name:  award.v.01  #####\n",
      "POS : verb.possession\n",
      "Definition : give, especially as an honor or reward\n",
      "Lemmas:  ['award', 'present']\n",
      "##### Synset name:  give.v.08  #####\n",
      "POS : verb.possession\n",
      "Definition : give as a present; make a gift of\n",
      "Lemmas:  ['give', 'gift', 'present']\n",
      "##### Synset name:  deliver.v.01  #####\n",
      "POS : verb.communication\n",
      "Definition : deliver (a speech, oration, or idea)\n",
      "Lemmas:  ['deliver', 'present']\n",
      "##### Synset name:  introduce.v.01  #####\n",
      "POS : verb.communication\n",
      "Definition : cause to come to know personally\n",
      "Lemmas:  ['introduce', 'present', 'acquaint']\n",
      "##### Synset name:  portray.v.04  #####\n",
      "POS : verb.creation\n",
      "Definition : represent abstractly, for example in a painting, drawing, or sculpture\n",
      "Lemmas:  ['portray', 'present']\n",
      "##### Synset name:  confront.v.03  #####\n",
      "POS : verb.communication\n",
      "Definition : present somebody with something, usually to accuse or criticize\n",
      "Lemmas:  ['confront', 'face', 'present']\n",
      "##### Synset name:  present.v.12  #####\n",
      "POS : verb.communication\n",
      "Definition : formally present a debutante, a representative of a country, etc.\n",
      "Lemmas:  ['present']\n",
      "##### Synset name:  salute.v.06  #####\n",
      "POS : verb.communication\n",
      "Definition : recognize with a gesture prescribed by a military regulation; assume a prescribed position\n",
      "Lemmas:  ['salute', 'present']\n",
      "##### Synset name:  present.a.01  #####\n",
      "POS : adj.all\n",
      "Definition : temporal sense; intermediate between past and future; now existing or happening or in consideration\n",
      "Lemmas:  ['present']\n",
      "##### Synset name:  present.a.02  #####\n",
      "POS : adj.all\n",
      "Definition : being or existing in a specified place\n",
      "Lemmas:  ['present']\n"
     ]
    }
   ],
   "source": [
    "# synsets 객체가 가지는 속성\n",
    "for synset in synsets:\n",
    "    print('##### Synset name: ', synset.name(), ' #####')\n",
    "    print('POS :', synset.lexname())\n",
    "    print('Definition :', synset.definition())\n",
    "    print('Lemmas: ', synset.lemma_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree</th>\n",
       "      <th>lion</th>\n",
       "      <th>tiger</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lion</th>\n",
       "      <td>0.07</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiger</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tree  lion  tiger   cat   dog\n",
       "tree   1.00  0.07   0.07  0.08  0.12\n",
       "lion   0.07  1.00   0.33  0.25  0.17\n",
       "tiger  0.07  0.33   1.00  0.25  0.17\n",
       "cat    0.08  0.25   0.25  1.00  0.20\n",
       "dog    0.12  0.17   0.17  0.20  1.00"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# WordNet은 어떤 어휘와 다른 어휘 간의 관계를 유사도로 나타냄\n",
    "# 유사도를 나타내기 위해 path_similarity() 메소드 제공\n",
    "# synset 객체를 단어별로 생성\n",
    "\n",
    "tree = wn.synset('tree.n.01')\n",
    "lion = wn.synset('lion.n.01')\n",
    "tiger = wn.synset('tiger.n.02')\n",
    "cat = wn.synset('cat.n.01')\n",
    "dog = wn.synset('dog.n.01')\n",
    "\n",
    "entities = [tree , lion , tiger , cat , dog]\n",
    "similarities = []\n",
    "entity_names = [ entity.name().split('.')[0] for entity in entities ]\n",
    "\n",
    "# 단어별 synset 들을 iteration 하면서 다른 단어들의 synset과 유사도를 측정 \n",
    "for entity in entities:\n",
    "    similarity = [ round(entity.path_similarity(compared_entity), 2)  for compared_entity in entities ]\n",
    "    similarities.append(similarity)\n",
    "    \n",
    "# 개별 단어별 synset과 다른 단어의 synset과의 유사도를 DataFrame형태로 저장합니다.  \n",
    "similarity_df = pd.DataFrame(similarities , columns=entity_names,index=entity_names)\n",
    "similarity_df\n",
    "# lion은 tree와의 유사도가 가장 적고 tiger와는 유사도가 가장 큼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q. tree, dog, cat 과 유사도가 높은 단어를 구하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = wn.synset('tree.n.01')\n",
    "cat = wn.synset('cat.n.01')\n",
    "dog = wn.synset('dog.n.01')\n",
    "\n",
    "all = wn.synset('*.n.01')\n",
    "\n",
    "entities = []\n",
    "entities.append(all)\n",
    "\n",
    "similarities = []\n",
    "entity_names = [ entity.name().split('.')[0] for entity in entities ]\n",
    "\n",
    "for entity in entities:\n",
    "    similarity = [ round(entity.path_similarity(compared_entity), 2)  for compared_entity in entities ]\n",
    "    similarities.append(similarity)\n",
    "    \n",
    "# 개별 단어별 synset과 다른 단어의 synset과의 유사도를 DataFrame형태로 저장합니다.  \n",
    "similarity_df = pd.DataFrame(similarities , columns=entity_names,index=entity_names)\n",
    "similarity_df\n",
    "\n",
    "\"\"\"\n",
    "def similarity(word):\n",
    "    tree = wn.synset('tree.n.01')\n",
    "    cat = wn.synset('cat.n.01')\n",
    "    dog = wn.synset('dog.n.01')\n",
    "    \n",
    "    word = [tree, cat, dog]\n",
    "    \n",
    "    if word.path_similarity([compared_word for compared_word in input_words]) >= 0.8:\n",
    "        return print(compared_word)\n",
    "\n",
    "    \n",
    "any_word = []\n",
    "\n",
    "i = 0\n",
    "for i<10:\n",
    "    random = input(\"enter word(10 words):\")\n",
    "    any_word.append(random)\n",
    "\n",
    "similarity(any_word)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VADER lexicon을 이용한 Sentiment Analysis\n",
    "- SenitimentIntensityAnalyzer 클래스를 이용하여 쉽게 갑성 분석 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import  nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  sentiment                                             review\n",
      "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
      "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
      "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['id', 'sentiment', 'review'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "review_df = pd.read_csv('./dataset/labeledTrainData.tsv', header = 0, sep = '\\t', quoting = 3)\n",
    "print(review_df.head(3))\n",
    "review_df.shape\n",
    "review_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"\n"
     ]
    }
   ],
   "source": [
    "print(review_df.review[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df/series에서 str 적용 문자열 연산 수행 \n",
    "import re\n",
    "# <br> html 태그는 replace 함수로 공백으로 변환\n",
    "review_df.review = review_df.review.str.replace('<br />',' ')\n",
    "# 파이썬의 정규 표현식 모듈인 re를 이용하여 영어 문자열이 아닌 문자는 \n",
    "# 모두 공백으로 변환\n",
    "review_df.review = review_df.review.apply(lambda x : re.sub('[^a-zA-Z]', ' ',x))\n",
    "# review_df.review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " With all this stuff going down at the moment with MJ i ve started listening to his music  watching the odd documentary here and there  watched The Wiz and watched Moonwalker again  Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent  Moonwalker is part biography  part feature film which i remember going to see at the cinema when it was originally released  Some of it has subtle messages about MJ s feeling towards the press and also the obvious message of drugs are bad m kay   Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring  Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him   The actual feature film bit when it finally starts is only on for    minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord  Why he wants MJ dead so bad is beyond me  Because MJ overheard his plans  Nah  Joe Pesci s character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno  maybe he just hates MJ s music   Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence  Also  the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene   Bottom line  this movie is for people who like MJ on one level or another  which i think is most people   If not  then stay away  It does try and give off a wholesome message and ironically MJ s bestest buddy in this movie is a girl  Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty  Well  with all the attention i ve gave this subject    hmmm well i don t know because people can be different behind closed doors  i know this for a fact  He is either an extremely nice but stupid guy or one of the most sickest liars  I hope he is not the latter  \n"
     ]
    }
   ],
   "source": [
    "print(review_df.review[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.082, 'neu': 0.691, 'pos': 0.227, 'compound': 0.9783}\n"
     ]
    }
   ],
   "source": [
    "# NLTK 서브모듈로 SentimentIntensityAnalyzer 임포트, IMDB 감상평 감성 분석\n",
    "# neg는 부정, neu는 중립, pos는 긍정, compound는 조합한 감성지수\n",
    "# compound score는 -1 ~1 사이의 감성지수를 표현, 0.1 이상이면 긍정 감성\n",
    "# 그 이하는 부정 감성으로 판단하나 사오하엥 따라 임계값을 조정해 예측 성능 조절\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "senti_anlayzer = SentimentIntensityAnalyzer()\n",
    "senti_scores = senti_anlayzer.polarity_scores(review_df.review[1])\n",
    "print(senti_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   The Classic War of the Worlds   by Timothy Hines is a very entertaining film that obviously goes to great effort and lengths to faithfully recreate H  G  Wells  classic book  Mr  Hines succeeds in doing so  I  and those who watched his film with me  appreciated the fact that it was not the standard  predictable Hollywood fare that comes out every year  e g  the Spielberg version with Tom Cruise that had only the slightest resemblance to the book  Obviously  everyone looks for different things in a movie  Those who envision themselves as amateur   critics   look only to criticize everything they can  Others rate a movie on more important bases like being entertained  which is why most people never agree with the   critics    We enjoyed the effort Mr  Hines put into being faithful to H G  Wells  classic novel  and we found it to be very entertaining  This made it easy to overlook what the   critics   perceive to be its shortcomings  '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.review[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q. https://www.imdb.com/chart/top/ 에서 ranking top 3와 ranking 248-250 영화에대한 user review에 대하여 비지도 학습으로 compound를 구하고 '긍정', '부정' 감성여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3 = '''\"The Godfather: Part II\" is a very suspenseful drama with a very exciting story, with great acting and great special effects. I would definitely recommend you watch this movie...but first watch the original classic from 1972 \"The Godfather\" . The movie may not be as good as the first movie but is still an amazing sequel.'''\n",
    "\n",
    "top248 = '''If you like James Cagney and you like the film noirs of the late 1940s, well, it doesn't get much better than this.\n",
    "\n",
    "Cagney, who was always great at playing wild gangsters, makes this film interesting all the way through its two hours. Despite being a half-century old, he was still not far from being at the top of his game. His character, Cody Jarrett, is one of the most famous of the many he portrayed on film, which is saying a lot.\n",
    "\n",
    "Who could sit on his mother's lap and still look like a tough guy? Not many, but Cagney pulled it off here with his tough mama, played really well by Margaret Wycherly. This was a new type of role for Wycherly, who was used to doing Shakespeare. You wouldn't know it from this \"Ma Jarrett\" role!\n",
    "\n",
    "The \"hoods\" in here are all realistic tough guys and gals. Cagney's two-faced wife is played well by Virginia Mayo, who plays the typical (for this genre) floozy blonde whom you can trust about as far as you can throw.\n",
    "\n",
    "The final scene - \"Top Of World, Ma!\" - is one of the most famous in all of film history. It's nice to see a nice print of this out on DVD now and some of the features are very informative. Included is an interview with Mayo, who still looks pretty good for an old lady!'''\n",
    "\n",
    "\n",
    "top249 = '''Washizu is a brave samurai who helps his lord to fight off a violent rebellion. Washizu and his friend Miki are riding through Cobweb Forest when a spirit appears to them and makes predictions which fire their ambitions. When Washizu explains this vision to his wife Asaji, she urges him to murder his lord and rule in his stead. Thus the tragedy begins.\n",
    "\n",
    "Kurosawa's interpretation of Macbeth is visually fascinating. Swirling mist, colossal trees dripping with rain, rich black volcanic soil and bulky fortress architecture provide the imposing, dread-laden backdrop against which the humans move in superbly stylized patterns. The director chose to shoot the action on Mount Fuji precisely because of the volcanic soil - and even had truckloads brought to the studio for pickup shots.\n",
    "\n",
    "Westerners unfamiliar with Noh are missing a huge part of the film's meaning. This thousand-year-old theatrical tradition corresponds broadly to our Elizabethan Tragedy, and Kurosawa shows how the two cultural strains, eastern and western, interlock and interact. The one illumines the other.\n",
    "\n",
    "The Noh stage must have on it three pine branches and a symbolic Shinto temple-arch. In the film, shots are carefully composed to include tangles of branches in the foreground, and the vast entrance gate of Washizu's fortress serves for the temple arch. And yet Kurosawa is not including these details redundantly, for mere form's sake - the ubiquitous branches, framing the human action, remind us all the time of the forest nemesis awaiting Washizu. The arch is Washizu's interface with the world - open in the early stages, but gradually less so as the protagonist retreats into his own diseased inner self.\n",
    "\n",
    "A Noh play features a \"doer\" (Shite) and a \"companion\" (Waku) who plays a subordinate role. Washizu and Asaji are the Shite and Waku respectively. Elements in the Noh include a battle-drama (we get one here) and a so-called \"wig drama\", in which a female character dominates the action. This is the central portion of the film, in the quiet of the fortress quarters, when Asaji ruthlessly manipulates her husband's ambition. Every Noh play has a ghost which appears to the Shite, and the spirit in the forest fulfils that function. Noh plays are never original works, in that (by a venerable convention) they are re-workings of ancient legends. Kurosawa follows tradition by quarrying his tale from Shakespeare's play.\n",
    "\n",
    "There is no western term to describe the stylized striking of poses so important in Noh. Our word \"dance\" is a crude word which approximates to, but does not convey, the grace of the Japanese art-form. Asaji, alone with the blood-stain, gives us a glimpse of this delightful ritual.\n",
    "\n",
    "Finally, Noh contains an aural richness almost totally absent from western tragedy - the complex rhythms of stamping and percussion which accompany the spoken word. In the film, the rhythmic patterns of horses' hooves on soil, and Washizu's bare feet on the boards of the banquet hall, are meant to reinforce the mood as they creep into our emotions by subliminal insistence.\n",
    "\n",
    "Isuzu Yamada is terrific as Asaji. Her stillness absolutely oozes determination, contrasting strongly with her husband's hollow bluster.\n",
    "\n",
    "It seems that Kurosawa cherished the concept of a Noh Macbeth for some years before committing it to celluloid. Apparently the project had to be scrapped in 1952 because Welles' Macbeth was nearing completion, and Kurosawa did not want the two films to suffer by being endlessly compared. This version, then, had to wait until 1957 to be realised.\n",
    "\n",
    "The director is not afraid to add his own flourishes to the well-known story. We hear of the notorious traitor Fujimaki who disembowelled himself in a room of the fortress. The exact spot is now known as the Forbidden Room, a place of evil omen with its indelible bloodstain on the floor. It is a symbol which encapsulates the spirit of the film, interweaving the related themes of treachery, blood and guilt. In a brilliant transition, we are taken to a change of scene by the ripping down of a banner by galloping horsemen. Washizu at the pinnacle of his arrogance is filmed from below with severe foreshortening, conveying his vainglory more effectively than words ever could. The death scene, with its railing, hysterical protagonist and relentless volleys of arrows (their grouped shafts recalling the fateful forest) has enormous power and lives long in the viewer's memory.'''\n",
    "\n",
    "\n",
    "top250 = '''Set in Cappadochia, central Anatolia, WINTER SLEEP (KIS UYKUSU) focuses on the life of Aydın (Haluk Bilginer) a retired actor who now runs the Hotel Othello. The name is significant, as it reveals his true preoccupation with performance, a trait reinforced by the framed bills on his study wall. With plenty of family money at his disposal he has no need to work, but that does not stop him from screwing every penny out of his tenants with the help of his henchperson Hidayet (Ayberk Pekcan). Although perpetually drawing attention to his poor background and unhappy childhood, it's clear that Aydın's life revolves totally around himself; and that the only way he can salve his conscience is to make charitable donations, preferably anonymously.\n",
    "\n",
    "With KIŞ UYKUSU we are back on thematic territory that director Nuri Bilge Ceylan previously explored in KASABA. He readily acknowledges Chekhov as an inspiration for creating a world where no one has much to do except talk to one another. Aydın busies himself with a variety of tasks, including writing a column for the local newspaper and writing a book on the history of the Turkish theater. His sister Necla (Demet Akbağ) spends much of her time lolling on the sofa and wondering whether she should forgive her ex-husband for an unhappy marriage. Aydın's wife Nihal (Melissa Sözen) is equally indolent; her sole aim in life seems to be to chair a committee of prosperous locals dedicated to raising money for the local school.\n",
    "\n",
    "Stylistically speaking KIŞ UYKUSU is slightly different from Ceylan's earlier work; there are fewer reflective sequences designed to prompt reflection on the landscape and the elements, and more face-to-face confrontations between the protagonists. They emphasize the basic emptiness of their lives, as they have nothing to but talk and talk, in contrast to their tenants - for example the local imam Hamdi (Serhat Kılıç) who wonders about taking a second job so as to make ends meet. On the other hand these lengthy conversations draw attention to the protagonists' love of surfaces; unable (or unwilling) to engage with life's realities, they would rather talk at rather than with one another.\n",
    "\n",
    "The unbelievable landscapes of Cappadochia in winter, with its fairy chimneys and unspoiled Anatolian terrain, offers a point of contrast to the characters' musings. While they spend their time both literally and mentally imprisoned within Aydın's hotel, the landscape offers a reminder of timeless virtues, as well as the fact that nature continues to flourish in spite of humanity's best attempts to destroy it.\n",
    "\n",
    "The film comes to a climactic conclusion when Ceylan brings the indolent characters into contact with those forced to eke out an existence in harsh conditions. Nihal offers a financial gift to Hamdi's family; but fails to understand how such an act of apparent goodwill represents the ultimate insult. As Hamdi's brother İsmail (Nejat İsler) contends, it is nothing more than conscience money to atone for the fact that Aydın's family were responsible for causing İsmail's son Ilyas's (Emirhan Doruktutan's) pneumonia earlier on in the film. Meanwhile Aydın discovers to his cost that the local educator Levent (Nadir Sarıbacak) has a jaundiced view of all wealthy philanthropists.\n",
    "\n",
    "Yet such experiences do not lead to any form of redemption. The film ends with Aydın and Nihal sitting morosely in their deserted hotel, looking out of the window at the snow-covered vista beyond, imprisoned by their lack of perception.\n",
    "\n",
    "This film won the Palme d'Or at Cannes; it deserves every success. A modern classic.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.026, 'neu': 0.668, 'pos': 0.305, 'compound': 0.9427}\n",
      "{'neg': 0.025, 'neu': 0.781, 'pos': 0.195, 'compound': 0.9916}\n",
      "{'neg': 0.104, 'neu': 0.798, 'pos': 0.099, 'compound': -0.7901}\n",
      "{'neg': 0.092, 'neu': 0.786, 'pos': 0.121, 'compound': 0.961}\n"
     ]
    }
   ],
   "source": [
    "# NLTK 서브모듈로 SentimentIntensityAnalyzer 임포트, IMDB 감상평 감성 분석\n",
    "# neg는 부정, neu는 중립, pos는 긍정, compound는 조합한 감성지수\n",
    "# compound score는 -1 ~1 사이의 감성지수를 표현, 0.1 이상이면 긍정 감성\n",
    "# 그 이하는 부정 감성으로 판단하나 사오하엥 따라 임계값을 조정해 예측 성능 조절\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "senti_anlayzer = SentimentIntensityAnalyzer()\n",
    "senti_scores1 = senti_anlayzer.polarity_scores(top3)\n",
    "senti_scores2 = senti_anlayzer.polarity_scores(top248)\n",
    "senti_scores3 = senti_anlayzer.polarity_scores(top249)\n",
    "senti_scores4 = senti_anlayzer.polarity_scores(top250)\n",
    "print(senti_scores1)\n",
    "print(senti_scores2)\n",
    "print(senti_scores3)\n",
    "print(senti_scores4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 사용자 함수\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print()\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1: {3:.4f}'.format(accuracy, precision, recall, f1))\n",
    "\n",
    "#get_clf_eval(y_target, vader_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER 예측 성능 평가 : \n",
      "오차 행렬\n",
      "[[ 6736  5764]\n",
      " [ 1867 10633]]\n",
      "\n",
      "정확도: 0.6948, 정밀도: 0.6485, 재현율: 0.8506, F1: 0.7359\n"
     ]
    }
   ],
   "source": [
    "# VADER를 이용한 IMDB 감성 분석 수행\n",
    "def vader_polarity(review, threshold=0.1):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(review)\n",
    "    # compound 값에 기반해 threshold 입력값보다 크면 1, 아니면 0을 반환\n",
    "    agg_score = scores['compound']\n",
    "    final_sentiment = 1 if agg_score >= threshold else 0\n",
    "    return final_sentiment\n",
    "\n",
    "review_df.vader_preds = review_df.review.apply(lambda x:vader_polarity(x,0.1))\n",
    "y_target = review_df.sentiment.values\n",
    "vader_preds = review_df.vader_preds.values\n",
    "\n",
    "print('VADER 예측 성능 평가 : ')\n",
    "\n",
    "get_clf_eval(y_target, vader_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
