{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트 분석 수행 프로세스\n",
    "#### 20 뉴스그룹 데이터 세트를 이용, 텍스트 분류\n",
    "- 특정 문서의 분류를 학습 데이터를 통해 학습해 모델을 생성한 뒤 이 학습 모델을 이용해 다른 문서의 분류를 예측\n",
    "- 텍스트를 피처 벡터화로 변환, 희소 행렬로 만들고 로지스틱 회귀를 이용해 분류 수행\n",
    "- Count 기반 과 TF-IDF 기반의 벡터화를 각각 적용, 성능 비교\n",
    "- 피처 벡터화를 위한 파라미터와 GridSearchCV 기반의 하이퍼파라미터 튜닝을 일괄적으로 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 정규화\n",
    "# scikit-learn이 제공하는 데이터셋 다운로드 받기\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "news_data = fetch_20newsgroups(subset='all', random_state=156)\n",
    "print(news_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#news_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    999\n",
       "15    997\n",
       "8     996\n",
       "9     994\n",
       "11    991\n",
       "13    990\n",
       "7     990\n",
       "5     988\n",
       "14    987\n",
       "2     985\n",
       "12    984\n",
       "3     982\n",
       "6     975\n",
       "1     973\n",
       "4     963\n",
       "17    940\n",
       "16    910\n",
       "0     799\n",
       "18    775\n",
       "19    628\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "len(news_data.data)\n",
    "pd.Series(news_data.target).value_counts()\n",
    "# 20개 개수대로 sort돼서 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _20newsgroups_dataset:\\n\\nThe 20 newsgroups text dataset\\n------------------------------\\n\\nThe 20 newsgroups dataset comprises around 18000 newsgroups posts on\\n20 topics split in two subsets: one for training (or development)\\nand the other one for testing (or for performance evaluation). The split\\nbetween the train and test set is based upon a messages posted before\\nand after a specific date.\\n\\nThis module contains two loaders. The first one,\\n:func:`sklearn.datasets.fetch_20newsgroups`,\\nreturns a list of the raw texts that can be fed to text feature\\nextractors such as :class:`sklearn.feature_extraction.text.CountVectorizer`\\nwith custom parameters so as to extract feature vectors.\\nThe second one, :func:`sklearn.datasets.fetch_20newsgroups_vectorized`,\\nreturns ready-to-use features, i.e., it is not necessary to use a feature\\nextractor.\\n\\n**Data Set Characteristics:**\\n\\n    =================   ==========\\n    Classes                     20\\n    Samples total            18846\\n    Dimensionality               1\\n    Features                  text\\n    =================   ==========\\n\\nUsage\\n~~~~~\\n\\nThe :func:`sklearn.datasets.fetch_20newsgroups` function is a data\\nfetching / caching functions that downloads the data archive from\\nthe original `20 newsgroups website`_, extracts the archive contents\\nin the ``~/scikit_learn_data/20news_home`` folder and calls the\\n:func:`sklearn.datasets.load_files` on either the training or\\ntesting set folder, or both of them::\\n\\n  >>> from sklearn.datasets import fetch_20newsgroups\\n  >>> newsgroups_train = fetch_20newsgroups(subset=\\'train\\')\\n\\n  >>> from pprint import pprint\\n  >>> pprint(list(newsgroups_train.target_names))\\n  [\\'alt.atheism\\',\\n   \\'comp.graphics\\',\\n   \\'comp.os.ms-windows.misc\\',\\n   \\'comp.sys.ibm.pc.hardware\\',\\n   \\'comp.sys.mac.hardware\\',\\n   \\'comp.windows.x\\',\\n   \\'misc.forsale\\',\\n   \\'rec.autos\\',\\n   \\'rec.motorcycles\\',\\n   \\'rec.sport.baseball\\',\\n   \\'rec.sport.hockey\\',\\n   \\'sci.crypt\\',\\n   \\'sci.electronics\\',\\n   \\'sci.med\\',\\n   \\'sci.space\\',\\n   \\'soc.religion.christian\\',\\n   \\'talk.politics.guns\\',\\n   \\'talk.politics.mideast\\',\\n   \\'talk.politics.misc\\',\\n   \\'talk.religion.misc\\']\\n\\nThe real data lies in the ``filenames`` and ``target`` attributes. The target\\nattribute is the integer index of the category::\\n\\n  >>> newsgroups_train.filenames.shape\\n  (11314,)\\n  >>> newsgroups_train.target.shape\\n  (11314,)\\n  >>> newsgroups_train.target[:10]\\n  array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])\\n\\nIt is possible to load only a sub-selection of the categories by passing the\\nlist of the categories to load to the\\n:func:`sklearn.datasets.fetch_20newsgroups` function::\\n\\n  >>> cats = [\\'alt.atheism\\', \\'sci.space\\']\\n  >>> newsgroups_train = fetch_20newsgroups(subset=\\'train\\', categories=cats)\\n\\n  >>> list(newsgroups_train.target_names)\\n  [\\'alt.atheism\\', \\'sci.space\\']\\n  >>> newsgroups_train.filenames.shape\\n  (1073,)\\n  >>> newsgroups_train.target.shape\\n  (1073,)\\n  >>> newsgroups_train.target[:10]\\n  array([0, 1, 1, 1, 0, 1, 1, 0, 0, 0])\\n\\nConverting text to vectors\\n~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\\nIn order to feed predictive or clustering models with the text data,\\none first need to turn the text into vectors of numerical values suitable\\nfor statistical analysis. This can be achieved with the utilities of the\\n``sklearn.feature_extraction.text`` as demonstrated in the following\\nexample that extract `TF-IDF`_ vectors of unigram tokens\\nfrom a subset of 20news::\\n\\n  >>> from sklearn.feature_extraction.text import TfidfVectorizer\\n  >>> categories = [\\'alt.atheism\\', \\'talk.religion.misc\\',\\n  ...               \\'comp.graphics\\', \\'sci.space\\']\\n  >>> newsgroups_train = fetch_20newsgroups(subset=\\'train\\',\\n  ...                                       categories=categories)\\n  >>> vectorizer = TfidfVectorizer()\\n  >>> vectors = vectorizer.fit_transform(newsgroups_train.data)\\n  >>> vectors.shape\\n  (2034, 34118)\\n\\nThe extracted TF-IDF vectors are very sparse, with an average of 159 non-zero\\ncomponents by sample in a more than 30000-dimensional space\\n(less than .5% non-zero features)::\\n\\n  >>> vectors.nnz / float(vectors.shape[0])\\n  159.01327...\\n\\n:func:`sklearn.datasets.fetch_20newsgroups_vectorized` is a function which \\nreturns ready-to-use token counts features instead of file names.\\n\\n.. _`20 newsgroups website`: http://people.csail.mit.edu/jrennie/20Newsgroups/\\n.. _`TF-IDF`: https://en.wikipedia.org/wiki/Tf-idf\\n\\n\\nFiltering text for more realistic training\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\\nIt is easy for a classifier to overfit on particular things that appear in the\\n20 Newsgroups data, such as newsgroup headers. Many classifiers achieve very\\nhigh F-scores, but their results would not generalize to other documents that\\naren\\'t from this window of time.\\n\\nFor example, let\\'s look at the results of a multinomial Naive Bayes classifier,\\nwhich is fast to train and achieves a decent F-score::\\n\\n  >>> from sklearn.naive_bayes import MultinomialNB\\n  >>> from sklearn import metrics\\n  >>> newsgroups_test = fetch_20newsgroups(subset=\\'test\\',\\n  ...                                      categories=categories)\\n  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\\n  >>> clf = MultinomialNB(alpha=.01)\\n  >>> clf.fit(vectors, newsgroups_train.target)\\n  MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\\n\\n  >>> pred = clf.predict(vectors_test)\\n  >>> metrics.f1_score(newsgroups_test.target, pred, average=\\'macro\\')\\n  0.88213...\\n\\n(The example :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py` shuffles\\nthe training and test data, instead of segmenting by time, and in that case\\nmultinomial Naive Bayes gets a much higher F-score of 0.88. Are you suspicious\\nyet of what\\'s going on inside this classifier?)\\n\\nLet\\'s take a look at what the most informative features are:\\n\\n  >>> import numpy as np\\n  >>> def show_top10(classifier, vectorizer, categories):\\n  ...     feature_names = np.asarray(vectorizer.get_feature_names())\\n  ...     for i, category in enumerate(categories):\\n  ...         top10 = np.argsort(classifier.coef_[i])[-10:]\\n  ...         print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\\n  ...\\n  >>> show_top10(clf, vectorizer, newsgroups_train.target_names)\\n  alt.atheism: edu it and in you that is of to the\\n  comp.graphics: edu in graphics it is for and of to the\\n  sci.space: edu it that is in and space to of the\\n  talk.religion.misc: not it you in is that and to of the\\n\\n\\nYou can now see many things that these features have overfit to:\\n\\n- Almost every group is distinguished by whether headers such as\\n  ``NNTP-Posting-Host:`` and ``Distribution:`` appear more or less often.\\n- Another significant feature involves whether the sender is affiliated with\\n  a university, as indicated either by their headers or their signature.\\n- The word \"article\" is a significant feature, based on how often people quote\\n  previous posts like this: \"In article [article ID], [name] <[e-mail address]>\\n  wrote:\"\\n- Other features match the names and e-mail addresses of particular people who\\n  were posting at the time.\\n\\nWith such an abundance of clues that distinguish newsgroups, the classifiers\\nbarely have to identify topics from text at all, and they all perform at the\\nsame high level.\\n\\nFor this reason, the functions that load 20 Newsgroups data provide a\\nparameter called **remove**, telling it what kinds of information to strip out\\nof each file. **remove** should be a tuple containing any subset of\\n``(\\'headers\\', \\'footers\\', \\'quotes\\')``, telling it to remove headers, signature\\nblocks, and quotation blocks respectively.\\n\\n  >>> newsgroups_test = fetch_20newsgroups(subset=\\'test\\',\\n  ...                                      remove=(\\'headers\\', \\'footers\\', \\'quotes\\'),\\n  ...                                      categories=categories)\\n  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\\n  >>> pred = clf.predict(vectors_test)\\n  >>> metrics.f1_score(pred, newsgroups_test.target, average=\\'macro\\')\\n  0.77310...\\n\\nThis classifier lost over a lot of its F-score, just because we removed\\nmetadata that has little to do with topic classification.\\nIt loses even more if we also strip this metadata from the training data:\\n\\n  >>> newsgroups_train = fetch_20newsgroups(subset=\\'train\\',\\n  ...                                       remove=(\\'headers\\', \\'footers\\', \\'quotes\\'),\\n  ...                                       categories=categories)\\n  >>> vectors = vectorizer.fit_transform(newsgroups_train.data)\\n  >>> clf = MultinomialNB(alpha=.01)\\n  >>> clf.fit(vectors, newsgroups_train.target)\\n  MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\\n\\n  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\\n  >>> pred = clf.predict(vectors_test)\\n  >>> metrics.f1_score(newsgroups_test.target, pred, average=\\'macro\\')\\n  0.76995...\\n\\nSome other classifiers cope better with this harder version of the task. Try\\nrunning :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py` with and without\\nthe ``--filter`` option to compare the results.\\n\\n.. topic:: Recommendation\\n\\n  When evaluating text classifiers on the 20 Newsgroups data, you\\n  should strip newsgroup-related metadata. In scikit-learn, you can do this by\\n  setting ``remove=(\\'headers\\', \\'footers\\', \\'quotes\\')``. The F-score will be\\n  lower because it is more realistic.\\n\\n.. topic:: Examples\\n\\n   * :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py`\\n\\n   * :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " news_data.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터 크기 11314, 테스트 데이터 크기 7532\n"
     ]
    }
   ],
   "source": [
    "# 순수한 텍스트만으로 구성된 기사 내용으로 어떤 뉴스그룹에 속하는지 분류\n",
    "#from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# 텍스트 정규화\n",
    "# 뉴스그룹 기사 내용을 제외하고 다른 정보 제거\n",
    "# 제목, 소속, 이메일 등 헤더와 푸터 정보들은 분류의 타겟 클래스 값과 유사할 수 있음\n",
    "train_news = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), random_state=156)\n",
    "x_train = train_news.data\n",
    "y_train = train_news.target\n",
    "\n",
    "test_news = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), random_state=156)\n",
    "x_test = test_news.data\n",
    "y_test = test_news.target\n",
    "\n",
    "print('학습데이터 크기 {0}, 테스트 데이터 크기 {1}'.format(len(train_news.data), len(test_news.data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     319\n",
      "1     389\n",
      "2     394\n",
      "3     392\n",
      "4     385\n",
      "5     395\n",
      "6     390\n",
      "7     396\n",
      "8     398\n",
      "9     397\n",
      "10    399\n",
      "11    396\n",
      "12    393\n",
      "13    396\n",
      "14    394\n",
      "15    398\n",
      "16    364\n",
      "17    376\n",
      "18    310\n",
      "19    251\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "import numpy as np\n",
    "print(pd.Series(y_test).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 101631)\n",
      "(7532, 101631)\n"
     ]
    }
   ],
   "source": [
    "# 피처 벡터화 변환과 머신러닝 모델 학습/예측/평가\n",
    "# CountVectorizer으로 feature extraction 변환 수행\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cnt_vect = CountVectorizer()\n",
    "cnt_vect.fit(x_train, y_train)\n",
    "x_train_cnt_vect = cnt_vect.transform(x_train)\n",
    "\n",
    "# 학습 데이터로 fit()된 CountVectorizer를 반드시 이용하여 테스트 데이터 feature extraction 변환 수행(피처 개수가 동일해야 함)\n",
    "x_test_cnt_vect = cnt_vect.transform(x_test)\n",
    "\n",
    "print(x_train_cnt_vect.shape)\n",
    "print(x_test_cnt_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6079394583112055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# 로지스틱 회귀를 적용, 뉴스그룹에 대한 분류 예측\\n\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score\\nimport warnings\\nwarnings.filterwarnings('ignore')\\n\\nlr_clf = LogisticRegression()\\nlr_clf.fit(X_train_cnt_vect, y_train)\\nlr_pred = lr_clf.predict(X_test_cnt_vect)\\nprint(accuracy_score(y_test, lr_pred))\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVect-Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train_cnt_vect, y_train)\n",
    "lr_pred = lr.predict(x_test_cnt_vect)\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "\n",
    "print(lr_accuracy)\n",
    "\n",
    "\"\"\"\n",
    "# 로지스틱 회귀를 적용, 뉴스그룹에 대한 분류 예측\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_cnt_vect, y_train)\n",
    "lr_pred = lr_clf.predict(X_test_cnt_vect)\n",
    "print(accuracy_score(y_test, lr_pred))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 101631)\n",
      "(7532, 101631)\n",
      "0.6079394583112055\n"
     ]
    }
   ],
   "source": [
    "# 피처 벡터화 변환과 머신러닝 모델 학습/예측/평가\n",
    "# Count Vectorization으로 feature extraction 변환 수행. \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cnt_vect = CountVectorizer()\n",
    "cnt_vect.fit(x_train,y_train)\n",
    "X_train_cnt_vect = cnt_vect.transform(x_train)\n",
    "# 학습 데이터로 fit( )된 CountVectorizer를 반드시 이용하여 테스트 데이터 \n",
    "# feature extraction 변환 수행(피처 개수가 동일해야 함)\n",
    "X_test_cnt_vect = cnt_vect.transform(x_test)\n",
    "print(X_train_cnt_vect.shape)\n",
    "print(X_test_cnt_vect.shape)\n",
    "\n",
    "# 로지스틱 회귀를 적용, 뉴스그룹에 대한 분류 예측\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_cnt_vect, y_train)\n",
    "lr_pred = lr_clf.predict(X_test_cnt_vect)\n",
    "print(accuracy_score(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 101631)\n",
      "(7532, 101631)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vect.fit(x_train)\n",
    "x_train_tfidf_vect = tfidf_vect.transform(x_train)\n",
    "\n",
    "# 학습 데이터로 fit()된 CountVectorizer를 반드시 이용하여 테스트 데이터 feature extraction 변환 수행(피처 개수가 동일해야 함)\n",
    "x_test_tfidf_vect = tfidf_vect.transform(x_test)\n",
    "\n",
    "print(x_train_tfidf_vect.shape)\n",
    "print(x_test_tfidf_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6736590546999469\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Vect - Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train_tfidf_vect, y_train)\n",
    "lr_pred = lr.predict(x_test_tfidf_vect)\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "\n",
    "print(lr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 943737)\n",
      "(7532, 943737)\n",
      "\n",
      "0.6868029739776952\n"
     ]
    }
   ],
   "source": [
    "# 더 높은 정확도를 위해 불용어 제거\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "tfidf_vect.fit(x_train)\n",
    "x_train_tfidf_vect = tfidf_vect.transform(x_train)\n",
    "\n",
    "# 학습 데이터로 fit()된 CountVectorizer를 반드시 이용하여 테스트 데이터 feature extraction 변환 수행(피처 개수가 동일해야 함)\n",
    "x_test_tfidf_vect = tfidf_vect.transform(x_test)\n",
    "\n",
    "print(x_train_tfidf_vect.shape)\n",
    "print(x_test_tfidf_vect.shape)\n",
    "print()\n",
    "\n",
    "# TF-IDF Vect - Logistic Regression\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(x_train_tfidf_vect, y_train)\n",
    "lr_pred = lr.predict(x_test_tfidf_vect)\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "\n",
    "print(lr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "\n",
    "# 30분 이상 걸림\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# 최적 C 값 도출 튜닝 수행. CV는 3 Fold셋으로 설정.\n",
    "params = {'C':[5,10]}\n",
    "gcv_lr = GridSearchCV(\n",
    "    lr_clf\n",
    "    , param_grid=params\n",
    "    # 교차 검증 폴드 수\n",
    "    , cv=3\n",
    "    , scoring='accuracy'\n",
    "    , verbose = 1)\n",
    "\n",
    "gcv_lr.fit(x_train_tfidf_vect, y_train)\n",
    "print(gcv_lr.best_params_)\n",
    "\n",
    "# 최적 C 값으로 학습된 grid_cv로 예측 수행하고 정확도 평가.\n",
    "lr_pred = gcv_lr.predict(X_test_tfidf_vect)\n",
    "print(accuracy_score(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30분 이상 소요\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer(stop_words='english')),\n",
    "    ('lr_clf', LogisticRegression())\n",
    "])\n",
    "# 하이퍼파라미터명이 개게 변수명과 결합 : 피처 벡터화 객체 파라미터와 Estimator 객체의 하이퍼파라미터 구별하기 위함\n",
    "params = {'tfidf_vect__ngram_range':[(1,1),(1,2),(1,3)],\n",
    "         'tfidf_vect__max_df':[100,300,700],\n",
    "         'lr_clf__C':[1,5,10]}\n",
    "\n",
    "grid_cv_pipe = GridSearchCV(pipeline, param_grid=params, cv=3, \\\n",
    "                           scoring = 'accuracy', verbose = 1)\n",
    "grid_cv_pipe.fit(x_train,y_train)\n",
    "print(grid_cv_pipe.best_params_, grid_cv_pripe.best_score_)\n",
    "\n",
    "pred = grid_cv_pipe.predict(x_test)\n",
    "print(accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 뉴스기사의 카테고리 판정 - 네이버 뉴스 2400개 수집"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 모듈은 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf.py : TF-IDF로 텍스트를 벡터로 변환하는 모듈\n",
    "from konlpy.tag import Okt\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# KoNLPy의 Okt객체 초기화 \n",
    "okt = Okt()\n",
    "# 전역 변수 \n",
    "word_dic = {'_id': 0} # 단어 사전\n",
    "dt_dic = {} # 문장 전체에서의 단어 출현 횟수\n",
    "files = [] # 문서들을 저장할 리스트\n",
    "\n",
    "def tokenize(text):\n",
    "    '''KoNLPy로 형태소 분석하기''' \n",
    "    result = []\n",
    "    word_s = okt.pos(text, norm=True, stem=True)\n",
    "    for n, h in word_s:\n",
    "        if not (h in ['Noun', 'Verb ', 'Adjective']): continue\n",
    "        if h == 'Punctuation' and h2 == 'Number': continue\n",
    "        result.append(n)\n",
    "    return result\n",
    "\n",
    "def words_to_ids(words, auto_add = True):\n",
    "    ''' 단어를 ID로 변환하기 ''' \n",
    "    result = []\n",
    "    for w in words:\n",
    "        if w in word_dic:\n",
    "            result.append(word_dic[w])\n",
    "            continue\n",
    "        elif auto_add:\n",
    "            id = word_dic[w] = word_dic['_id']\n",
    "            word_dic['_id'] += 1\n",
    "            result.append(id)\n",
    "    return result\n",
    "\n",
    "def add_text(text):\n",
    "    '''텍스트를 ID 리스트로 변환해서 추가하기''' \n",
    "    ids = words_to_ids(tokenize(text))\n",
    "    files.append(ids)\n",
    "\n",
    "def add_file(path):\n",
    "    '''텍스트 파일을 학습 전용으로 추가하기''' \n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        s = f.read()\n",
    "        add_text(s)\n",
    "\n",
    "def calc_files():\n",
    "    '''추가한 파일 계산하기''' \n",
    "    global dt_dic\n",
    "    result = []\n",
    "    doc_count = len(files)\n",
    "    dt_dic = {}\n",
    "    # 단어 출현 횟수 세기\n",
    "    for words in files:\n",
    "        used_word = {}\n",
    "        data = np.zeros(word_dic['_id'])\n",
    "        for id in words:\n",
    "            data[id] += 1\n",
    "            used_word[id] = 1\n",
    "        # 단어 t가 사용되고 있을 경우 dt_dic의 수를 1 더하기 \n",
    "        for id in used_word:\n",
    "            if not(id in dt_dic): dt_dic[id] = 0\n",
    "            dt_dic[id] += 1\n",
    "        # 정규화하기 \n",
    "        data = data / len(words) \n",
    "        result.append(data)\n",
    "    # TF-IDF 계산하기 \n",
    "    for i, doc in enumerate(result):\n",
    "        for id, v in enumerate(doc):\n",
    "            idf = np.log(doc_count / dt_dic[id]) + 1\n",
    "            doc[id] = min([doc[id] * idf, 1.0])\n",
    "        result[i] = doc\n",
    "    return result\n",
    "\n",
    "def save_dic(fname):\n",
    "    '''사전을 파일로 저장하기''' \n",
    "    pickle.dump(\n",
    "        [word_dic, dt_dic, files],\n",
    "        open(fname, \"wb\"))\n",
    "\n",
    "def load_dic(fname):\n",
    "    '''사전 파일 읽어 들이기''' \n",
    "    global word_dic, dt_dic, files\n",
    "    n = pickle.load(open(fname, 'rb'))\n",
    "    word_dic, dt_dic, files = n\n",
    "\n",
    "def calc_text(text):\n",
    "    ''' 문장을 벡터로 변환하기 ''' \n",
    "    data = np.zeros(word_dic['_id'])\n",
    "    words = words_to_ids(tokenize(text), False)\n",
    "    for w in words:\n",
    "        data[w] += 1\n",
    "    data = data / len(words)\n",
    "    for id, v in enumerate(data):\n",
    "        idf = np.log(len(files) / dt_dic[id]) + 1\n",
    "        data[id] = min([data[id] * idf, 1.0])\n",
    "    return data\n",
    "# 모듈 테스트하기 \n",
    "if __name__ == '__main__':\n",
    "    add_text('비')\n",
    "    add_text('오늘은 비가 내렸어요.') \n",
    "    add_text('오늘은 더웠지만 오후부터 비가 내렸다.') \n",
    "    add_text('비가 내리는 일요일이다.') \n",
    "    print(calc_files())\n",
    "    print(word_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 뉴스 정치, 경제, 생활, IT/과학 기사 TF-IDF 벡터 변환 후 genre.pickle로 저장\n",
    "# 텍스트 분류 과정\n",
    "# 1. 텍스트에서 불필요한 품사를 제거\n",
    "# 2. 사전을 기반으로 단어를 숫자로 변환\n",
    "# 3. 파일 내부의 단어 출현 비율을 계산\n",
    "# 4. 데이터를 학습\n",
    "\n",
    "# makedb_tfidf.py : 문장의 형태소를 벡터로 변환\n",
    "import os, glob, pickle\n",
    "import tfidf\n",
    "\n",
    "# 변수 초기화\n",
    "y = []\n",
    "x = []\n",
    "\n",
    "# 디렉터리 내부의 파일 목록 전체에 대해 처리하기 \n",
    "def read_files(path, label):\n",
    "    print(\"read_files=\", path)\n",
    "    files = glob.glob(path + \"/*.txt\")\n",
    "    for f in files:\n",
    "        if os.path.basename(f) == 'LICENSE.txt': continue\n",
    "        tfidf.add_file(f)\n",
    "        y.append(label)\n",
    "\n",
    "# 기사를 넣은 디렉터리 읽어 들이기 \n",
    "read_files('dataset/100', 0)\n",
    "read_files('dataset/101', 1)\n",
    "read_files('dataset/103', 2)\n",
    "read_files('dataset/105', 3)\n",
    "\n",
    "\n",
    "# TF-IDF 벡터로 변환하기 \n",
    "x = tfidf.calc_files()\n",
    "\n",
    "# 저장하기 \n",
    "pickle.dump([y, x], open('dataset/genre.pickle', 'wb'))\n",
    "tfidf.save_dic('dataset/genre-tdidf.dic')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3197\n",
      "3197\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "\n",
    "# TF-IDF 데이터베이스 읽어 들이기\n",
    "data = pickle.load(open('./dataset/genre.pickle', 'rb'))\n",
    "\n",
    "# 레이블\n",
    "y = data[0]\n",
    "\n",
    "# TF-IDF\n",
    "x= data[1]\n",
    "\n",
    "print(len(y))\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.8\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89       138\n",
      "           1       0.80      0.70      0.75       169\n",
      "           2       0.72      0.89      0.80       160\n",
      "           3       0.82      0.74      0.78       173\n",
      "\n",
      "    accuracy                           0.80       640\n",
      "   macro avg       0.81      0.81      0.80       640\n",
      "weighted avg       0.81      0.80      0.80       640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 학습, 테스트 분할\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y\n",
    "    , test_size=0.2\n",
    ")\n",
    "\n",
    "# 모델 생성(나이브 베이지안, 가우시안)\n",
    "model = GaussianNB()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# 모델 평가, 결과 출력\n",
    "y_pred = model.predict(x_test)\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "rep = metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "print('accuracy = ', acc)\n",
    "print()\n",
    "print(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 분류할 레이블 수\n",
    "nb_classes = 4\n",
    "\n",
    "# read database\n",
    "data = pickle.load(open('./dataset/genre.pickle', 'rb'))\n",
    "\n",
    "# label\n",
    "y = data[0]\n",
    "# TF-IDF\n",
    "x = data[1]\n",
    "\n",
    "#import pandas as pd\n",
    "#print(pd.Series(y).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(36120,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(np.array(y)))\n",
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2557 samples, validate on 640 samples\n",
      "Epoch 1/10\n",
      "2557/2557 [==============================] - 4s 1ms/step - loss: 0.8486 - accuracy: 0.7270 - val_loss: 0.4104 - val_accuracy: 0.8500\n",
      "Epoch 2/10\n",
      "2557/2557 [==============================] - 3s 1ms/step - loss: 0.2303 - accuracy: 0.9280 - val_loss: 0.3343 - val_accuracy: 0.8750\n",
      "Epoch 3/10\n",
      "2557/2557 [==============================] - 3s 1ms/step - loss: 0.0953 - accuracy: 0.9734 - val_loss: 0.3270 - val_accuracy: 0.8844\n",
      "Epoch 4/10\n",
      "2557/2557 [==============================] - 3s 1ms/step - loss: 0.0463 - accuracy: 0.9855 - val_loss: 0.3343 - val_accuracy: 0.8953\n",
      "Epoch 5/10\n",
      "2557/2557 [==============================] - 4s 1ms/step - loss: 0.0225 - accuracy: 0.9934 - val_loss: 0.3930 - val_accuracy: 0.8844\n",
      "Epoch 6/10\n",
      "2557/2557 [==============================] - 3s 1ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.4298 - val_accuracy: 0.8828\n",
      "Epoch 7/10\n",
      "2557/2557 [==============================] - 3s 1ms/step - loss: 0.0079 - accuracy: 0.9965 - val_loss: 0.4278 - val_accuracy: 0.8875\n",
      "Epoch 8/10\n",
      "2557/2557 [==============================] - 3s 1ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.4845 - val_accuracy: 0.8797\n",
      "Epoch 9/10\n",
      "2557/2557 [==============================] - 4s 1ms/step - loss: 0.0064 - accuracy: 0.9973 - val_loss: 0.5320 - val_accuracy: 0.8844\n",
      "Epoch 10/10\n",
      "2557/2557 [==============================] - 4s 1ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.5118 - val_accuracy: 0.8891\n",
      "640/640 [==============================] - 0s 500us/step\n",
      "정답률= 0.8890625238418579 loss= 0.5118399925064295\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de3zU9Z3v8dcnd0JCgCRcAwQBEa8gAUFqtbUXtV1t6zmuWlrraUt3t+26PbWnuqfbi/vYrXtO27Xd7c22WLdWebh2t+vZpVtrK9uLokkEFVDkYkICAoEESICEZOZz/vj9QiYhwACTzOQ37+fjMY+Z323mMz/Ie37z/X3n+zN3R0REoisn3QWIiMjQUtCLiEScgl5EJOIU9CIiEaegFxGJOAW9iEjEKehFRCJOQS+RYWZrzKzNzArTXYtIJlHQSySYWTVwFeDAjcP4unnD9VoiZ0tBL1HxYWAt8GPgjt6ZZjbKzL5uZo1mdtDMfm9mo8JlbzGzZ83sgJk1mdlHwvlrzOxjCc/xETP7fcK0m9knzWwLsCWc983wOQ6ZWb2ZXZWwfq6Z/aWZbTOz9nD5NDP7tpl9PfFNmNn/M7O/GIodJNlLQS9R8WHgp+Ht3WY2MZz/NWAhcCUwHvhfQNzMpgO/AP4BqATmA+vP4PXeB1wBXBhO14bPMR54FPhnMysKl/1P4DbgBmAM8D+AI8DDwG1mlgNgZhXAtcBjZ/LGRU5HQS8jnpm9BZgBPO7u9cA24PYwQP8HcJe773T3mLs/6+5dwAeBp939MXfvdvf97n4mQf9Vd29196MA7v5I+Bw97v51oBCYG677MeAL7r7ZAy+F674AHCQId4BbgTXuvuccd4lIPwp6iYI7gKfcfV84/Wg4rwIoIgj+gaadZH6ymhInzOyzZvZq2Dx0ACgLX/90r/UwsDx8vBz4yTnUJDIonUiSES1sb78FyDWz3eHsQmAsMBnoBGYBLw3YtAlYfJKnPQwUJ0xPGmSd48O+hu3xnyc4Mt/o7nEzawMs4bVmARsGeZ5HgA1mdhkwD/j5SWoSOWs6opeR7n1AjKCtfH54mwf8jqDdfiXwDTObEp4UXRp2v/wp8A4zu8XM8sys3Mzmh8+5HviAmRWb2Wzgo6epoRToAVqAPDP7IkFbfK8fAn9tZnMscKmZlQO4ezNB+/5PgJ/1NgWJpJKCXka6O4CH3H2Hu+/uvQH/SNAOfw/wCkGYtgJ/B+S4+w6Ck6OfDeevBy4Ln/PvgWPAHoKmlZ+epoZfEpzYfR1oJPgWkdi08w3gceAp4BDwI2BUwvKHgUtQs40MEdOFR0TSy8zeStCEU+3u8XTXI9GjI3qRNDKzfOAu4IcKeRkqCnqRNDGzecABgpPGD6S5HIkwNd2IiEScjuhFRCIu4/rRV1RUeHV1dbrLEBEZUerr6/e5e+VgyzIu6Kurq6mrq0t3GSIiI4qZNZ5smZpuREQiTkEvIhJxCnoRkYjLuDb6wXR3d9Pc3ExnZ2e6SxlyRUVFVFVVkZ+fn+5SRCQiRkTQNzc3U1paSnV1NWZ2+g1GKHdn//79NDc3M3PmzHSXIyIRcdqmGzNbaWZ7zWywIVYJR+P7lpltNbOXzezyhGV3mNmW8HbHYNsno7Ozk/Ly8kiHPICZUV5enhXfXERk+CTTRv9j4LpTLL8emBPeVgDfBTCz8cCXCC63thj4kpmNO9tCox7yvbLlfYrI8Dlt0427/9bMqk+xyk3AP3kwlsJaMxtrZpOBa4BfuXsrgJn9iuADQ9fDFJGs4e509cQ53NXD4a4YHV09HD7Wc3z6cFdPMK+rh/KSQm6/YnrKa0hFG/1U+o+93RzOO9n8E5jZCoJvA0yfnvo3mQoHDhzg0Ucf5c/+7M/OaLsbbriBRx99lLFjxw5RZSKZJRZ3unpidHbHT7zvjtHZE6ezO0ZXT5zunji5OUZujpGfa+Tm5JCXY+TlBvPycnISlgXTeblGXs7g0/m5OeF8O6dvx8fCYE4M5Y6EUD7S1cPhY7HjAd17fzzIu3o4krC8J57cmGILpo/N2KAfbG/6KeafONP9QeBBgJqamowcZe3AgQN85zvfOSHoY7EYubm5J91u9erVQ12aRIC7E3eIuwe3eMJj71sei/sJ63o4f+C6p3quIIzjdIWh2xu8vfddCdODBnZ439kToyuc7gqnu2OZ8SecY5CXmzPoh8DAaXeOh/qRrhjHYsmNGJ2fa4wuzGN0QR4lhXmMLsyltCiPSWOKGF2YR0lhbrC8sHd537zihG16l+XnDk2P91QEfTPBxY97VQG7wvnXDJi/JgWvlxb33HMP27ZtY/78+eTn51NSUsLkyZNZv349mzZt4n3vex9NTU10dnZy1113sWLFCqBvSIeOjg6uv/563vKWt/Dss88ydepU/u3f/o1Ro0ad5pUlk8TiTkdXD+2d3bR39oS37uP3hwaZN3C97ng8COKEcM5ERfk5FObl9rsvys+lMC+H0YV5jB+dQ2E4XZSfS1FeLoX5OQn3wfKifvOC+97ny8/NIe7QE4vTEw8+gHri3m+6OxZPmO/0xPtPx+LxhGWDT3fH+p47Fo8nLAueHzgetqcL6NEFvevlUph38oO8TJKKoH8S+JSZrSI48XrQ3d80s18Cf5twAvZdwL3n+mJf+X8b2bTr0Lk+TT8XThnDl/7oolOuc//997NhwwbWr1/PmjVreM973sOGDRuOd4NcuXIl48eP5+jRoyxatIibb76Z8vLyfs+xZcsWHnvsMX7wgx9wyy238LOf/Yzly5en9L3IycXiTkdnD4cGhnBXXxgfOkmA987r6Oo57esU5OZQWpQX3vIpLcqjuqKY0qJ8SgrzKMzLwczIMcgxIycn4bERLjNyc4J5/dY1wvX7r5vMcw1ctzegE+97g7u3RomG0wa9mT1GcGReYWbNBD1p8gHc/XvAaoJrb24FjgB3hstazeyvCa7VCXBf74nZKFi8eHG/vu7f+ta3+Nd//VcAmpqa2LJlywlBP3PmTObPD64/vXDhQhoaGoat3mxy4MgxXt/Twet72tmyp50tezt4fU8H+zq6TrvtYCFdUTH6+OPSonzGFOUxJmF64PpF+SPjKE+yRzK9bm47zXIHPnmSZSuBlWdX2uBOd+Q9XEaPHn388Zo1a3j66ad57rnnKC4u5pprrhm0L3xhYeHxx7m5uRw9enRYao2qg0e72bKnvS/U9waPW9r7An10QS5zJpby9gsqmVw2ilKFtGShEfHL2ExQWlpKe3v7oMsOHjzIuHHjKC4u5rXXXmPt2rXDXF20HeocEOh7Otiyt509h/oCvbgglzkTSrj6/ErOn1jCnImlnD+xlCllRWqCkKynoE9SeXk5y5Yt4+KLL2bUqFFMnDjx+LLrrruO733ve1x66aXMnTuXJUuWpLHSkau9s5steztOCPXdh/q+HY3Kz2X2hBKWza7g/ImlQahPKGXq2FHk5CjQRQaTcdeMramp8YEXHnn11VeZN29emioaflF/vx1dPUHbeXhk/vqeINx3HewL9KL8HGZPKOH8CaXh0XkQ6FXjFOgigzGzenevGWyZjuhlyLg7W/d2sL7pQHhCNAj3nQf6zk0U5OUwu7KExTPHH29uOX9iCVXjislVoIukhIJeUqqp9QjPbdvPH7bt49lt+4+fGC3IzeG8ytEsnDGO2xZPOx7q08cr0EWGmoJezklLexfPbd/Ps1uDYN/RegSAipJCrpxVzpWzyqmpHk91eTF5Q/SrPxE5NQW9nJFDnd08v72VZ7ft49mt+9m8J+iJVFqUx5LzyrlzWTXLZlcwZ0KJeruIZAgFvZxSZ3eMuoY2nt22jz9s288rzQeIOxTm5bCoejw3LZjClbMquHjKGB2xi2QoBb300x2L83LzweNNMfU72jjWEycvx7hs2lg+9bbZLJ1VweUzxo6YcT5Esp2CPklnO0wxwAMPPMCKFSsoLi4egsrOTTzuvLa7PWiK2bafF95oPT6ey4WTx3DH0hlcOauCRTPHU1Ko/y4iI5H+cpN0smGKk/HAAw+wfPnyjAh6d6dh/5HjbezPbd9P6+FjAJxXMZqb5k9h2ewKlpxXzvjRBWmuVkRSQUGfpMRhit/5zncyYcIEHn/8cbq6unj/+9/PV77yFQ4fPswtt9xCc3MzsViMv/qrv2LPnj3s2rWLt73tbVRUVPDMM88Me+27D3YGbexb9/Pctn3Hf5g0aUwR18ytZNmsCpbOKmfKWA2ZLBJFIy/of3EP7H4ltc856RK4/v5TrpI4TPFTTz3FE088wQsvvIC7c+ONN/Lb3/6WlpYWpkyZwn/8x38AwRg4ZWVlfOMb3+CZZ56hoqIitXWfQlPrER787Xb+sG0f21sOAzCuOJ+ls8r501kVLJtVzsyK0eoZI5IFRl7QZ4CnnnqKp556igULFgDQ0dHBli1buOqqq7j77rv5/Oc/z3vf+16uuuqqtNS3raWDD/7geQ4cPcbS88q5bdF0rpxdzrxJYzR8gEgWGnlBf5oj7+Hg7tx777184hOfOGFZfX09q1ev5t577+Vd73oXX/ziF4e1ti172rntB8/j7vz8k8u4YNKYYX19Eck86vicpMRhit/97nezcuVKOjo6ANi5cyd79+5l165dFBcXs3z5cu6++25efPHFE7YdSq++eYhbH1yLGaxasUQhLyLASDyiT5PEYYqvv/56br/9dpYuXQpASUkJjzzyCFu3buVzn/scOTk55Ofn893vfheAFStWcP311zN58uQhOxm7YedBlv/oeYrycnn041dwXmXJkLyOiIw8GqY4A53p+123o40Pr3yBMUX5PPbxJUwvT383ThEZXhqmOMJqG1q586FayksKePTjS5iqLpIiMoCCfgR7dts+PvZwHZPKinj0Y0uYVFaU7pJEJAONmJOxmdbENFSSfZ+/fb2FOx+qZerYUaxaoZAXkZMbEUFfVFTE/v37Ix/27s7+/fspKjp1aP/mtT187OE6zqssYdWKJUwoVciLyMmNiKabqqoqmpubaWlpSXcpQ66oqIiqqqqTLv/PDbv59GMvcsGkMfzko4sZW6zxaETk1EZE0Ofn5zNz5sx0l5F2//7yLu5atZ5Lq8r48Z2LKRuVn+6SRGQEGBFBL/Cv65r57OMvUTNjPCvvXKQhg0UkaUqLEeDx2iY+/y8vs/S8cn54Rw3FBfpnE5HkKTEy3CNrG/nCzzfw1vMrefBDCynK11WdROTMJNXrxsyuM7PNZrbVzO4ZZPkMM/u1mb1sZmvMrCphWczM1oe3J1NZfNSt/P0bfOHnG7j2ggkKeRE5a6c9ojezXODbwDuBZqDWzJ50900Jq30N+Cd3f9jM3g58FfhQuOyou89Pcd2R973/2sb9v3iN6y6axLduW0BB3ojoCSsiGSiZ9FgMbHX37e5+DFgF3DRgnQuBX4ePnxlkuZyBb/16C/f/4jX+6LIp/MPtCnkROTfJJMhUoClhujmcl+gl4Obw8fuBUjMrD6eLzKzOzNaa2fsGewEzWxGuU5cNfeVPxt35+lOb+cavXucDl0/lgT+eT36uQl5Ezk0yKTLYJYkG/kT1buBqM1sHXA3sBHrCZdPDEdVuBx4ws1knPJn7g+5e4+41lZWVyVcfIe7O/b94jX/4zVZuXTSNr/23y8jV1aBEJAWS6XXTDExLmK4CdiWu4O67gA8AmFkJcLO7H0xYhrtvN7M1wAJg2zlXHiHuzn3/vomH/tDAh5bM4Cs3XqRL/olIyiRzRF8LzDGzmWZWANwK9Os9Y2YVZtb7XPcCK8P548yssHcdYBmQeBI368Xjzhd+voGH/tDAR98yk/tuUsiLSGqdNujdvQf4FPBL4FXgcXffaGb3mdmN4WrXAJvN7HVgIvA34fx5QJ2ZvURwkvb+Ab11slos7nz+Zy/z0+d38KfXzOIL75mHmUJeRFJrRFxhKop6YnHu/ueX+Pn6Xdx17Rz+4h1zFPIictZ0hakM0x2L8xer1vMfr7zJ5949l0++bXa6SxKRCFPQD7OunhiffnQdT23aw/++YR4ff+t56S5JRCJOQT+MOrtj/Okj9TyzuYWv3HgRd1xZne6SRCQLKOiHydFjMVb8pI7fb93H377/Em6/Ynq6SxKRLKGgHwaHu3r46MO1PP9GK//n5kv57zXTTr+RiEiKKOiHWHtnN3c+VMu6pgM88MfzuWn+wNEjRESGloJ+CB080s2HH3qBjTsP8g+3LeCGSyanuyQRyUIK+iHSdvgYy3/0PK/vaec7H7ycd100Kd0liUiWUtAPgX0dXSz/4fNs33eYBz9cw9vmTkh3SSKSxRT0KXbwaDe3PriW5rYjPPSRRSybXZHukkQkyynoU+xXm/awdW8HD92pkBeRzKCrWqRYXUMrY4ryuHpOdo6rLyKZR0GfYnWNbVw+Y5yGGhaRjKGgT6G2w8fYureDRdXj012KiMhxCvoUqm9sA2DhjHFprkREpI+CPoXqGtvIzzUuqxqb7lJERI5T0KdQfWMrF00pY1RBbrpLERE5TkGfIl09MV5qPkiNmm1EJMMo6FNkw86DHOuJU6MTsSKSYRT0KVLboBOxIpKZFPQpUtfQRnV5MZWlhekuRUSkHwV9Crg79Y2tarYRkYykoE+BbS2HaTvSrROxIpKRFPQpUN/YCqAjehHJSAr6FKhtaGNccT6zKkenuxQRkRMo6FOgvrGNhTPGYaaBzEQk8yjoz9G+ji7e2HdYzTYikrGSCnozu87MNpvZVjO7Z5DlM8zs12b2spmtMbOqhGV3mNmW8HZHKovPBHVh/3mdiBWRTHXaoDezXODbwPXAhcBtZnbhgNW+BvyTu18K3Ad8Ndx2PPAl4ApgMfAlM4tUItY3tlKQl8MlVWXpLkVEZFDJHNEvBra6+3Z3PwasAm4asM6FwK/Dx88kLH838Ct3b3X3NuBXwHXnXnbmqGts49KpZRTmaSAzEclMyQT9VKApYbo5nJfoJeDm8PH7gVIzK09yW8xshZnVmVldS0tLsrWnXWd3jA07D7KwOlJfUkQkYpIJ+sG6kviA6buBq81sHXA1sBPoSXJb3P1Bd69x95rKypFzrdWXmg7QHXMWzdCJWBHJXHlJrNMMTEuYrgJ2Ja7g7ruADwCYWQlws7sfNLNm4JoB2645h3ozSp2uKCUiI0AyQV8LzDGzmQRH6rcCtyeuYGYVQKu7x4F7gZXhol8Cf5twAvZd4fJIqGtoZfaEEsaNLkh3KZml8xA0vwA71ga3rnaYdgVMXwLTl8KYyemuUCSrnDbo3b3HzD5FENq5wEp332hm9wF17v4kwVH7V83Mgd8Cnwy3bTWzvyb4sAC4z91bh+B9DLt43KlvbOOGSxRaHNoFO54Lg/052LMRPA6WC5MvhcJSWPcTeOH7wfpjZwSB3xv8FedDjn7SITJUkjmix91XA6sHzPtiwuMngCdOsu1K+o7wI2PL3g4OdfZkX7NNPA77NvcP9gM7gmX5o2HaIrj680GIT62BwpJgWawbdr8SbvccbPs1vLwqWDZqHExb0hf8U+ZDnoZ7FkmVpIJeTlQXDmS2KOq/iO3pgl3rEoJ9LXQeCJaNngAzlsKSPwtCeuIlkHuS/1K5+TD18uC29JPgDq3b+4J/x1p4/RfBunlFMHVhX/BXLYJRuuC6yNlS0J+l+oY2KkoKmFFenO5SUutoGzS90Be+O1+EWFewrOJ8uPDGvmaXcTPhbMf3MYPyWcFtwfJgXkcLNK3t+6bwh2/C774OGEy8qC/4py+BsqpTPr3IiBCPw5F90P4mtO+GnDyYfW3KX0ZBf5ZqG1tH/kBm7nCwqS9Yd6yFvZuCZTl5MGUBXLEiCNdpV8DoiqGtp6QS5v1RcAM4dhh21vfV99IqqP1hsKxsWhj8YfhXzlM7fzJiPXB4LxzZH3xYjsqypsfhEo8H+7g3wDt2B/ftb0L7noT5e8BjfdtNWaCgzxR7DnXS1HqUO5ZWp7uUMxOPBUGeGOyHdgbLCkph2mK46ANh+/pCKEjzt5WC0TDzrcENgpDau7Gv/jd+B6/8c7CsqKx/z54pl0N+UfpqH26xHjjccvJAaX8zCJWOvfT7KUvJJJhwQfBB2XtfOVdNZScTj8PR1pPv38QAj/ecuH1xebDPSyfBhAuhdCKUTg6mSyfDmClDUraC/izUjZQLgXcfDY+Iw1BvegG6DgXLSieHzSBhU8jEiyAnw4dxyM2DyZcFtys+EXwjOdDY/4Nry1PhugXB0VFv8E+7AopH4PmUeAwO7zvJkeHuvtvhvUFPp34MRlf2hcmU+cF9ycTgSP7ADmh5Lbi9+DB0H+nbtHRKEPgT5kHlBeH93OADNYrc4UhruH/fPPnRd/tuiHefuP2ocX2BXXlBsI+PB3h4K5mYtk4GCvqzUNfYSlF+DhdNyaD/9D3HgqP1XevgzfXB/Z5Nff8pK+fBxTf3BfvY6Wffvp4pzGBcdXC77NZg3pFWaHq+L/if+07Q1g/BH2PeqOCPLT+8zxsVHPnnJdzyiwZf7/h04nqn2C4n7+T7uF/b7KmODPf2/2rfa3Rl35HhpEsSAiUMl5JJUDIhOAmejHgcDu6Ava9By6t993UPQc/RvvXGTO0f/L3fAIrGJPuvNrzcg/NOiR+OJ3xY7gnmxY6duH3R2L59WjGnbx8nBnnJxIz/9qigPwv1jW1cVjWWgrw0tQnHusNQX98X7Hs29v1HLSqDyfOD3i3TlwZNMiPxaPZsFI+HudcHNwi+1fT2Gjr0JvR0Brfuo0GPop7O4AddHS2DLDs6+NfvZFnOIB8QhdB58NRf7XsDZOJFfWFeOjm8TQx6O+Wl+Ed6OTl9H5pzE8YdjMeDb00tr8HeV/vua/8Q7KteY6rCpp/eD4HwA6C3e22quQe9vxK/1ZysPby3M0GiorK+wJ5xZfitZ0r/ppSSicG/WwQo6M/Q4a4eNu46xJ9cfd7wvGCsO/jDenN9X7Dv2dj3n7ewLPhR0hV/Enw1n7Lg3HrDRE3+qOAPecaVZ7d9rCf8AAiDv7uz7wOhp7P/dPfRUyxLeFxUduLR9/Gv9hn2K+ucHBg/M7j1fnhC0KTU1pDwAbA5+Abwxu/6B2vZtDD8E84DVJziA8A9aF4crHlqYJAnftD0KiwLw3pScJCTuH97PyhLJqX//NMwU9CfoZeaDhCL+9BcUSrWE/zhJDa/7N6QEOpjwvbpFcERe2+oq7fJ0MnNg9ySoTsyHalycvu6x17wnr75vR8Ae19NaAJ6Dd74r/5NI2OnB8E/dlrQ3JYY5IlNRb0KSvuap6oWn3gSsyQM9wJdt3kwCvozVNvQhhlcPv0cT8TGeoJfmCY2v+x+pe8opaA0CPXFHw8CffJ8GH+eQl0yW+IHwLz39s2P9YTfAF7tfx6gaW14wnhy0NMr8ZtOYojrg/acKOjPUF1jK3MnllI2KsmTXBAc5ex7PQj03mDf/UrfkUtBSRDqNR8NQn3KfBg/S6Eu0ZGbBxWzg1vv7yRk2Cjoz0As7qzbcYCb5p+mr+u+LUG3xt5g3/1yX9e1/NFhqN/Z1/xSPluhLiJDRkF/Bl7bfYiOrh5qTnZFqTdfgqe/EgzYBZBfDJMuhcvv6DtRWj478/uri0ikKOjPQH14oZGagVeUat0Ov/kb2PBE0Ff7HV+B898dDr+rUBeR9FLQn4G6hjYmjimkalzYt7ZjL/z2/0LdSsjJh6s+C1f+uX4+LiIZRUF/BuoaWqmpHo91tcNz/wjP/mPQS+byDwdjsOvKSSKSgRT0Sdp54Cj7DrbzIVsL3/pRMDLdhe+Dt/9V0JNARCRDKeiTEY+z+3c/5tcFX2fa5pZgNMV3fDno9ysikuEU9KfiDlufhqe/zMI9G3jVqond/j1y51yrIQZEZMRQ0J9MUy08/WVo/D2Mq+bvRn+OV8a+nUfOP8sxU0RE0kS/0hmo5XVY9UH40TuCIQpu+BrtH3uW77cu4PLqIb7CkojIENARfa9Du2DNV2HdI8EPna75y2CY38IS1r3eQtxh0cl+KCUiksEU9Efb4Pd/D89/PxiTZvEn4K1397s+al1DKzkGC851IDMRkTTI3qDvPhqE+++/AZ2H4NJb4G1/GVx4YYC6xjbmTR5DSWH27i4RGbmyL7liPbD+p7DmfmjfBbPfCe/4UnA5tkF0x+KsbzrAf19YNcyFioikRvYEvTu89u/w6/uCIYOn1sDNP4Dqt5xys1ffPMSRYzEWDsWFRkREhkF2BH3D74Ouks21wUBjf/wIXPDepPrC1zUEA5npRKyIjFTRDvrdrwTDBm/9VXDh3z/6Fsz/YHARhCTVN7YxdewoJpdF4yLBIpJ9kko8M7sO+CaQC/zQ3e8fsHw68DAwNlznHndfbWbVwKvA5nDVte7+J6kp/RTaGuCZv4WXH4eiMcGwwVd84oyv6O7u1Da0snRW+dDUKSIyDE4b9GaWC3wbeCfQDNSa2ZPuvilhtS8Aj7v7d83sQmA1UB0u2+bu81Nb9kkc3hcMG1z7o2Ac+GV/Dm/5TDBG/FlobjvK3vYuamao2UZERq5kjugXA1vdfTuAma0CbgISg96BMeHjMmBXKotMyv5t8P2rofswLFgOV98DZVPP6SlrG1oBWDjwQiMiIiNIMkE/FWhKmG4GrhiwzpeBp8zs08Bo4B0Jy2aa2TrgEPAFd//dwBcwsxXACoDp06cnXXw/48+DxR+Hy26Fyrln9xwD1DW2UVqYx9xJpSl5PhGRdEhmrJvBuqb4gOnbgB+7exVwA/ATM8sB3gSmu/sC4H8Cj5rZmAHb4u4PunuNu9dUVlae2Ts4XqUF/eFTFPIA9Q1tLJgxjtwcjVQpIiNXMkHfDExLmK7ixKaZjwKPA7j7c0ARUOHuXe6+P5xfD2wDzj/XoofDwSPdbN7TziK1z4vICJdM0NcCc8xsppkVALcCTw5YZwdwLYCZzSMI+hYzqwxP5mJm5wFzgO2pKn4ovbgj6D+/UP3nRWSEO20bvbv3mNmngF8SdJ1c6e4bzew+oM7dnwQ+C/zAzD5D0KzzEXd3M3srcJ+Z9QAx4E/cvXXI3k0K1Ta0kptjzJ+mC32LyMiWVD96d19N0GUycd4XEx5vApYNst3PgJ+dY41pUdfYxsVTxlBcELXjuYAAAArrSURBVO3flIlI9OnCI4M41hPnpaYD6lYpIpGgoB/Ehl0H6eqJU6P2eRGJAAX9IOrDgcz0i1gRiQIF/SDqGluZPr6YCWOK0l2KiMg5U9AP4O7UNbSp2UZEIkNBP0DD/iPsP3yMGp2IFZGIUNAP0DuQmY7oRSQqFPQD1De0UTYqn9mVJekuRUQkJRT0A9Q1trJwxjhyNJCZiESEgj5B6+FjbGs5rGYbEYkUBX2C+sbe/vM6ESsi0aGgT1DX0Ep+rnFpVVm6SxERSRkFfYK6xjYumVpGUX5uuksREUkZBX2oszvGK80HqalWs42IRIuCPvTKzoMci8U1vo2IRI6CPlQXDmS2UEEvIhGjoA/VN7ZyXsVoyksK012KiEhKKeiBeNypa9RAZiISTQp6YPu+Dg4c6Vb/eRGJJAU9UNvbPq8jehGJIAU9wYnY8aMLOK9idLpLERFJOQU9wYnYhTPGYaaBzEQkerI+6Fvau2jYf4RFarYRkYjK+qCvbwwuNLJQJ2JFJKKyPuhrG9ooyMvh4qlj0l2KiMiQyPqgr2tsY37VWArzNJCZiERTVgf90WMxNu48qG6VIhJpSQW9mV1nZpvNbKuZ3TPI8ulm9oyZrTOzl83shoRl94bbbTazd6ey+HO1vukAPXHXiVgRibS8061gZrnAt4F3As1ArZk96e6bElb7AvC4u3/XzC4EVgPV4eNbgYuAKcDTZna+u8dS/UbORu+J2MunK+hFJLqSOaJfDGx19+3ufgxYBdw0YB0Hes9mlgG7wsc3Aavcvcvd3wC2hs+XEeoa25gzoYSxxQXpLkVEZMgkE/RTgaaE6eZwXqIvA8vNrJngaP7TZ7AtZrbCzOrMrK6lpSXJ0s9NPO7UN7bpQiMiEnnJBP1gPxf1AdO3AT929yrgBuAnZpaT5La4+4PuXuPuNZWVlUmUdO5e39tOe2ePLjQiIpF32jZ6gqPwaQnTVfQ1zfT6KHAdgLs/Z2ZFQEWS26ZF70Bmi3RELyIRl8wRfS0wx8xmmlkBwcnVJwesswO4FsDM5gFFQEu43q1mVmhmM4E5wAupKv5c1De0UllayLTxo9JdiojIkDrtEb2795jZp4BfArnASnffaGb3AXXu/iTwWeAHZvYZgqaZj7i7AxvN7HFgE9ADfDJTetzUNbZRo4HMRCQLJNN0g7uvJjjJmjjviwmPNwHLTrLt3wB/cw41ptzug500tx3lzmUz012KiMiQy8pfxtaF/ed1IlZEskF2Bn1DG6Pyc7lwigYyE5Hoy86gb2xl/rSx5Odm5dsXkSyTdUnX0dXDpl2HqNH4NiKSJbIu6NfvOEDc0S9iRSRrZF3Q1zW2YgYLpo9NdykiIsMi64K+vrGNuRNLGVOUn+5SRESGRVYFfU8szouNbRr2QESySlYF/Wu72zl8LKYTsSKSVbIq6Osawh9K6YheRLJIdgV9YxuTy4qYOlYDmYlI9siaoHd36hraWKhhD0Qky2RN0O88cJTdhzp1IlZEsk7WBH19Y3ChER3Ri0i2yZqgr21opaQwjwsmlaa7FBGRYZU1QV/X0MaC6WPJ00BmIpJlsiL1DnV2s3lPu5ptRCQrZUXQv9jYhrsuBC4i2Skrgr6+sY3cHGP+NA1kJiLZJyuCvq6hjQsnj2F0YVKXyBURiZTIB313LM66Jv1QSkSyV+SDftOuQ3R2xzWQmYhkrcgHfW3vQGYzdCJWRLJT5IO+vrGNqnGjmFRWlO5SRETSItJB7+7UNbZRo/Z5EclikQ76Ha1HaGnv0vjzIpLVIh30dQ3BQGY6ESsi2SypoDez68xss5ltNbN7Bln+92a2Pry9bmYHEpbFEpY9mcriT6eusZXSojzOn6CBzEQke532F0Rmlgt8G3gn0AzUmtmT7r6pdx13/0zC+p8GFiQ8xVF3n5+6kpPXe6GRnBxLx8uLiGSEZI7oFwNb3X27ux8DVgE3nWL924DHUlHcuThw5Bhb9nboRKyIZL1kgn4q0JQw3RzOO4GZzQBmAr9JmF1kZnVmttbM3neS7VaE69S1tLQkWfqp9V5oRCdiRSTbJRP0g7V7+EnWvRV4wt1jCfOmu3sNcDvwgJnNOuHJ3B909xp3r6msrEyipNOra2wjL8e4rEoDmYlIdksm6JuBaQnTVcCuk6x7KwOabdx9V3i/HVhD//b7IVPf0MbFU8sYVZA7HC8nIpKxkgn6WmCOmc00swKCMD+h94yZzQXGAc8lzBtnZoXh4wpgGbBp4Lap1tUTY33zAbXPi4iQRK8bd+8xs08BvwRygZXuvtHM7gPq3L039G8DVrl7YrPOPOD7ZhYn+FC5P7G3zlDZsPMQx3o0kJmICCQR9ADuvhpYPWDeFwdMf3mQ7Z4FLjmH+s5KXTiQ2UINZCYiEs1fxtY1tlFdXkxlaWG6SxERSbvIBb27U9/Ypm6VIiKhyAX99n2HaT18TCdiRURCkQv6eg1kJiLST+SCvrahlXHF+cyqLEl3KSIiGSFyQV/fGAxkZqaBzEREIGJBv7+ji+37DqtbpYhIgkgFfV04kNkitc+LiBwXqaCvb2yjIDeHi6eWpbsUEZGMEamgr2to5dKqMoryNZCZiEivyAR9Z3eMV3YeZKGabURE+olM0Ld39nDDJZN565zUjGcvIhIVSQ1qNhJUlhbyzVuHZah7EZERJTJH9CIiMjgFvYhIxCnoRUQiTkEvIhJxCnoRkYhT0IuIRJyCXkQk4hT0IiIRZ+6e7hr6MbMWoPEcnqIC2JeickY67Yv+tD/60/7oE4V9McPdBx0aIOOC/lyZWZ2716S7jkygfdGf9kd/2h99or4v1HQjIhJxCnoRkYiLYtA/mO4CMoj2RX/aH/1pf/SJ9L6IXBu9iIj0F8UjehERSaCgFxGJuMgEvZldZ2abzWyrmd2T7nrSycymmdkzZvaqmW00s7vSXVO6mVmuma0zs39Pdy3pZmZjzewJM3st/D+yNN01pZOZfSb8O9lgZo+ZWVG6a0q1SAS9meUC3wauBy4EbjOzC9NbVVr1AJ9193nAEuCTWb4/AO4CXk13ERnim8B/uvsFwGVk8X4xs6nAnwM17n4xkAvcmt6qUi8SQQ8sBra6+3Z3PwasAm5Kc01p4+5vuvuL4eN2gj/kqemtKn3MrAp4D/DDdNeSbmY2Bngr8CMAdz/m7gfSW1Xa5QGjzCwPKAZ2pbmelItK0E8FmhKmm8niYEtkZtXAAuD59FaSVg8A/wuIp7uQDHAe0AI8FDZl/dDMRqe7qHRx953A14AdwJvAQXd/Kr1VpV5Ugt4GmZf1/UbNrAT4GfAX7n4o3fWkg5m9F9jr7vXpriVD5AGXA9919wXAYSBrz2mZ2TiCb/8zgSnAaDNbnt6qUi8qQd8MTEuYriKCX7/OhJnlE4T8T939X9JdTxotA240swaCJr23m9kj6S0prZqBZnfv/Yb3BEHwZ6t3AG+4e4u7dwP/AlyZ5ppSLipBXwvMMbOZZlZAcDLlyTTXlDZmZgRtsK+6+zfSXU86ufu97l7l7tUE/y9+4+6RO2JLlrvvBprMbG4461pgUxpLSrcdwBIzKw7/bq4lgien89JdQCq4e4+ZfQr4JcFZ85XuvjHNZaXTMuBDwCtmtj6c95fuvjqNNUnm+DTw0/CgaDtwZ5rrSRt3f97MngBeJOitto4IDoegIRBERCIuKk03IiJyEgp6EZGIU9CLiEScgl5EJOIU9CIiEaegFxGJOAW9iEjE/X8FQfE8D4+wSwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 레이블 데이터를 One-hot 형식 변환\n",
    "y = keras.utils.np_utils.to_categorical(y, nb_classes)\n",
    "in_size = x[0].shape[0]\n",
    "\n",
    "# 학습 전용과 테스트 전용으로 구분하기\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    np.array(x), np.array(y)\n",
    "    , test_size=0.2\n",
    ")\n",
    "\n",
    "# MLP모델의 구조 정의하기\n",
    "# 이진분류 : 시그모이드 활성화 함수와 하나의 유닛\n",
    "# 다중 분류 : 소프트맥스 활성화 함수와 k개의 유닛\n",
    "# 회귀 : 아무런 활성화 함수를 사용하지 않는 \n",
    "# dropout: 훈련도중 층의 출력 특성을 랜덤하게 유도\n",
    "# 0이 되는 특성의 비율 0.2~0.5\n",
    "# relu f(z) = max(0.z) z값이 0보다 크면 z가 되고 0보다 작으면 0이 됨\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(in_size,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "# 모델 컴파일하기\n",
    "# 손실 함수를 정의: 이진 크로스 엔트로피(이진 분류), 범주형 크로스 엔트로피(다중 분류)\n",
    "# 옵티마이저(가장 작은 손실 함수 오차를 만드는 모델 파라미터 값을 찾는 전략)\n",
    "# 확률적 경사 하강법, 모멘텀을 사용한 확률적 경사 하강법, RMSProp, Adam(Adaptive momentum)\n",
    "# compile 메소드와 metrics 매개변수를 지정하지 않으면 \n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=RMSprop(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# 학습 실행하기 \n",
    "hist = model.fit(x_train, y_train,\n",
    "          batch_size=128, \n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "# 평가하기 \n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"정답률=\", score[1], 'loss=', score[0])\n",
    "\n",
    "# 가중치데이터 저장하기 \n",
    "model.save_weights('./dataset/genre-model.hdf5')\n",
    "\n",
    "# 학습 상태를 그래프로 그리기\n",
    "# 모델 학습을 위해 fit() 함수를 사용하며 리턴값으로 학습 이력(History) 정보를 리턴\n",
    "# loss : 훈련 손실값\n",
    "# acc : 훈련 정확도\n",
    "# val_loss : 검증 손실값\n",
    "# val_acc : 검증 정확도\n",
    "# plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['accuracy'])\n",
    "# plt.plot(hist.history['val_loss'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "#plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "#plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Loss')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오버피팅(과적합)\n",
    "모델이 훈련 데이터에 매우 잘 맞지만 일반성이 떨어짐(test loss 우상향)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[text1]\n",
      "정치 ( 0.99999976 )\n",
      "\n",
      "[text2]\n",
      "IT/과학 ( 0.99498606 )\n",
      "\n",
      "[text3]\n",
      "생활  ( 0.9999747 )\n",
      "\n",
      "[text4]\n",
      "경제 ( 0.96317756 )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 기사 섹션 자동 판별\n",
    "\n",
    "import pickle, tfidf\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import model_from_json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 텍스트 준비하기 --- ( ※ 1)\n",
    "text1 = \"\"\"\n",
    "대통령이 북한과 관련된 이야기로 한미 정상회담을 준비하고 있습니다.\n",
    "\"\"\"\n",
    "text2 = \"\"\"\n",
    "iPhone과 iPad를 모두 가지고 다니므로 USB를 2개 연결할 수 있는 휴대용 배터리를 선호합니다.\n",
    "\"\"\"\n",
    "text3 = \"\"\"\n",
    "이번 주에는 미세먼지가 많을 것으로 예상되므로 노약자는 외출을 자제하는 것이 좋습니다.\n",
    "\"\"\"\n",
    "text4 = \"\"\"\n",
    "국내 개인투자자들의 주식투자 열풍이 불면서 최근 '동학개미운동'이라는 신조어까지 등장한 가운데, 개인투자자들도 향후 시장 움직임에 따른 투자전략을 준비할 필요성이 높아졌다.\n",
    "\"\"\"\n",
    "\n",
    "# TF-IDF 사전 읽어 들이기 --- (*2)\n",
    "tfidf.load_dic(\"./dataset/genre-tdidf.dic\")\n",
    "\n",
    "# Keras 모델 정의하고 가중치 데이터 읽어 들이기 --- (*3)\n",
    "nb_classes = 4\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(36120,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=RMSprop(),\n",
    "    metrics=['accuracy'])\n",
    "model.load_weights('./dataset/genre-model.hdf5')\n",
    "\n",
    "# 텍스트 지정해서 판별하기 --- (*4)\n",
    "def check_genre(text):\n",
    "    # 레이블 정의하기\n",
    "    LABELS = [\"정치\", \"경제\", \"생활 \", \"IT/과학\"]\n",
    "    # TF-IDF 벡터로 변환하기 -- (*5)\n",
    "    # 만들어놓은 모듈임\n",
    "    data = tfidf.calc_text(text)\n",
    "    # MLP로 예측하기 --- (*6)\n",
    "    pre = model.predict(np.array([data]))[0]\n",
    "    # argmax(): 최대치의 인덱스를 반환(정수)\n",
    "    n = pre.argmax()\n",
    "    print(LABELS[n], \"(\", pre[n], \")\")\n",
    "    # 인덱스에 해당하는 값, 가장 큰 값\n",
    "    return LABELS[n], float(pre[n]), int(n) \n",
    "\n",
    "# 기사 섹션 자동 판별\n",
    "if __name__ == '__main__':\n",
    "    print('[text1]'); check_genre(text1); print()\n",
    "    print('[text2]'); check_genre(text2); print()\n",
    "    print('[text3]'); check_genre(text3); print()\n",
    "    print('[text4]'); check_genre(text4); print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
