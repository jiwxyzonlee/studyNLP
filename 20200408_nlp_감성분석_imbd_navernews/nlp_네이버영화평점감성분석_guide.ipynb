{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네이버 영화 평점 train 데이터 기반으로 다음 사항에 유의하여 감성분석 후 test 데이터를 이용해 최종 감성 예측을 수행하세요. \n",
    "* 네이버 영화 평점 데이터는 http://github.com/e9t/nsmc에서 ratings.txt(전체), ratings._train.txt(학습), rating_test.txt(테스트)를 다운로드 \n",
    "* 데이터 세트 요약 정보\n",
    "\n",
    "  - 칼럼 : id, document\n",
    "  - label : the sentiment class of the review (0:negative, 1: positive)\n",
    "  - ratings.txt : All 200K reviews\n",
    "  - ratings_test : 50K reviews held out for testing\n",
    "  - ratings_train : 150K reviews for training\n",
    "  \n",
    "* 정규 표현식을 이용하여 숫자를 공백으로 변경(정규 표현식으로 \\d 는 숫자를 의미함.) \n",
    "* 테스트 데이터 셋을 로딩하고 동일하게 Null 및 숫자를 공백으로 변환\n",
    "* 한글 형태소 분석을 통해 형태소 단어로 토큰화(tokenizer 사용자 함수 작성 추천)\n",
    "  - 한글 형태소 엔진은 SNS 분석에 적합한 Okt 클래스를 이용\n",
    "  - morphs() 메서드는 입력 인자로 들어온 문장을 형태소 단어 형태로 토큰화해 list 객체 반환 \n",
    "  - Okt 객체의 morphs( ) 객체를 이용한 tokenizer를 사용. ngram_range는 (1,2)\n",
    "* 사이킷런의 TfidVectorizor를 이용, TF-IDF 피처 모델을 생성(10분 이상 소요)\n",
    "* DT, RF, LR 을 이용하여 감성 분석 Classification 수행\n",
    "* 3RO 분류 모델별 교차 검증 및 Parameter 최적화를 GridSearchCV 를 이용하여 수행(최적 분류 모델 선정)\n",
    "  - DT params = {'max_depth':[2,3,5,10], 'min_samples_split':[2,3,5],'min_samples_leaf':[1,5,8]}\n",
    "  - RF params = {'n_estimators':[50,100, 200], 'max_depth':[2,3,5], 'min_samples_leaf':[1,5,8]}  \n",
    "  - LR params = { 'C': [1 ,3.5, 4.5, 5.5, 10 ] }\\\n",
    "    C는 규제 강도를 조절하는 alpha 값의 역수로 작을 수록 규제 강도가 큼\n",
    "  - param_grid=params , cv=3 ,scoring='accuracy', verbose=1(학습진행 상황 표시) \n",
    "* 학습데이터에 사용된 TfidVectorizer 객체 변수인 tfidf_vect를 이용해 transform()을 테스트 데이터의 document 칼럼에 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('./dataset/nsmc/ratings_train.txt', sep='\\t')\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75173\n",
       "1    74827\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 3 columns):\n",
      "id          150000 non-null int64\n",
      "document    149995 non-null object\n",
      "label       150000 non-null int64\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25173\n",
       "0    24827\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('./dataset/nsmc/ratings_test.txt', sep='\\t')\n",
    "test_df.head(5)\n",
    "test_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 'document 칼럼에 Null이 일부 존재하므로 이 값은 공백으로 변환'\n",
    "train_df = train_df.fillna(' ')\n",
    "# 문자가 아닌 숫자의 경우 단어적인 의미로 부족하므로 \n",
    "# 정규 표현식을 이용하여 숫자를 공백으로 변경(정규 표현식으로 \\d 는 숫자를 의미함.) \n",
    "train_df['document'] = train_df['document'].apply( lambda x : re.sub(r\"\\d+\", \" \", x) )\n",
    "\n",
    "# 테스트 데이터 셋을 로딩하고 동일하게 Null 및 숫자를 공백으로 변환\n",
    "test_df = pd.read_csv('./dataset/nsmc/ratings_test.txt', sep='\\t')\n",
    "test_df = test_df.fillna(' ')\n",
    "test_df['document'] = test_df['document'].apply( lambda x : re.sub(r\"\\d+\", \" \", x) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# 한글 형태소 분석을 통해 형태소 단어로 토큰화\n",
    "# 한글 형태소 엔진은 SNS 분석에 적합한 Twitter 클래스를 이용\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "def okt_tokenizer(text):\n",
    "    # morphs() 메서드는 입력 인자로 들어온 text 를 형태소 단어로 토큰화 하여 list 객체 반환\n",
    "    tokens_ko = okt.morphs(text)\n",
    "    return tokens_ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런의 TfidVectorizor를 이용, TF-IDF 피처 모델을 생성(10분 소요)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 위에서 만든 tw_tokenizer() 함수를 tokenizer로 사용. ngram_range는 (1,2) \n",
    "tfidf_vect = TfidfVectorizer(tokenizer=okt_tokenizer, ngram_range=(1,2), min_df=3, \\\n",
    "                             max_df=0.9)\n",
    "tfidf_vect.fit(train_df['document'])\n",
    "tfidf_matrix_train = tfidf_vect.transform(train_df['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 3.5} 0.8592\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression 을 이용하여 감성 분석 Classification 수행.\n",
    "# 로지스틱 회귀의 하이퍼 파라미터 C를 설정\n",
    "# C는 규제 강도를 조절하는 alpha 값의 역수로 작을 수록 규제 강도가 크며\n",
    "# Penalty는 규제의 유형을 설정하며 l1 규제와 ㅣ2 규제가 있으며 기본은 l2 임\n",
    "lr_clf = LogisticRegression(random_state=0)\n",
    "\n",
    "# Parameter C 최적화를 위해 GridSearchCV 를 이용. \n",
    "params = { 'C': [1 ,3.5, 4.5, 5.5, 10 ] }\n",
    "gcv = GridSearchCV(lr_clf , param_grid=params , cv=3 ,scoring='accuracy', verbose=0 )\n",
    "gcv.fit(tfidf_matrix_train , train_df['label'] )\n",
    "print(gcv.best_params_ , round(gcv.best_score_,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 정확도:  0.86186\n"
     ]
    }
   ],
   "source": [
    "# 테스트 세트를 이용해 최종 감성 분석 예측 수행\n",
    "# 학습 데이터를 적용한 TfidfVectorizer 를 이용하여 테스트 데이터를 TF-IDF 값으로 Feature 변환함.\n",
    "# 이유는 학습 시 설정된 TfidVectorizer의 피처 개수와 테스트 데이터를 변환할 피처 개수가 같아야 하기 때문임 \n",
    "# 학습 데이터에 사용된 TfidfVectorizer 객체변수인 tfidf_vect를 이용해 transform()을 테스트 데이터의 document 칼럼에 수행\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "tfidf_matrix_test = tfidf_vect.transform(test_df['document'])\n",
    "\n",
    "# classifier 는 GridSearchCV에서 최적 파라미터로 학습된 classifier를 그대로 이용\n",
    "best_estimator = gcv.best_estimator_\n",
    "lr_preds = best_estimator.predict(tfidf_matrix_test)\n",
    "\n",
    "print('Logistic Regression 정확도: ',accuracy_score(test_df['label'],lr_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf을 이용하여 감성 분석 Classification 수행\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "params = {'n_estimators':[50,100, 200], 'max_depth':[2,3,5], 'min_samples_leaf':[1,5,8]}\n",
    "grid_cv = GridSearchCV(rf_clf, param_grid = params, cv=3, scoring= 'accuracy',verbose=0)\n",
    "grid_cv.fit(tfidf_matrix_train,train_df.label)\n",
    "print(grid_cv.best_params_, round(grid_cv.best_score_,4))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "tfidf_matrix_test = tfidf_vect.transform(test_df.document)\n",
    "best_estimator = grid_cv.best_estimator_\n",
    "rf_preds = best_estimator.predict(tfidf_matrix_test)\n",
    "print('rf 정확도:', accuracy_score(test_df.label,rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt를 이용하여 감성 분석 Classification 수행\n",
    "dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "params = {'max_depth':[2,3,5,10], 'min_samples_split':[2,3,5],\\\n",
    "              'min_samples_leaf':[1,5,8]}\n",
    "gcv_dt = GridSearchCV(dt_clf,param_grid = params, cv=3, scoring='accuracy',verbose=0)\n",
    "gcv_dt.fit(tfidf_matrix_train,train_df.label)\n",
    "print(gcv_dt.best_params_, round(gcv_dt.best_score_,4))\n",
    "\n",
    "tfidf_matrix_test = tfidf_vect.transform(test_df.document)\n",
    "best_estimator = grid_cv.best_estimator_\n",
    "dt_preds = best_estimator.predict(tfidf_matrix_test)\n",
    "print('dt 정확도:', accuracy_score(test_df.label,dt_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
