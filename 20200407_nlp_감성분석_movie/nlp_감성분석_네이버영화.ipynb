{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt 예측 정확도 : 0.7633587786259542\n"
     ]
    }
   ],
   "source": [
    "# ML 연습\n",
    "# DT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "t_df = pd.read_pickle('./dataset/t_df.pkl')\n",
    "\n",
    "y_df = t_df.survived\n",
    "X_df = t_df.drop('survived', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, \\\n",
    "                                                    test_size=0.2, \\\n",
    "                                                    random_state=11)\n",
    "dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "\n",
    "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
    "print('dt 예측 정확도 :', dt_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 예측 정확도 : 0.8206106870229007\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression(random_state=0)\n",
    "lr_clf.fit(X_train,y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "print('lr 예측 정확도 :', lr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[127  29]\n",
      " [ 33  73]]\n",
      "\n",
      "정확도: 0.7634, 정밀도: 0.7157, 재현율: 0.6887,    F1: 0.7019\n"
     ]
    }
   ],
   "source": [
    "# 평가 사용자 함수\n",
    "from sklearn.metrics import accuracy_score, precision_score , recall_score , \\\n",
    "confusion_matrix, f1_score\n",
    "def get_clf_eval(y_test , pred):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print()\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}'.format(accuracy, precision, recall, f1))\n",
    "    \n",
    "# get_clf_eval(y_test , lr_pred)\n",
    "get_clf_eval(y_test , dt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.7634\n",
      "교차 검증 1 정확도: 0.7634\n",
      "교차 검증 2 정확도: 0.7481\n",
      "교차 검증 3 정확도: 0.7710\n",
      "교차 검증 4 정확도: 0.7099\n",
      "교차 검증 5 정확도: 0.6870\n",
      "교차 검증 6 정확도: 0.6947\n",
      "교차 검증 7 정확도: 0.6870\n",
      "교차 검증 8 정확도: 0.7405\n",
      "교차 검증 9 정확도: 0.7692\n",
      "평균 정확도: 0.7334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# KFold 교차 검증 수행()\n",
    "# K개의 데이터 폴드 세트를 만들어서 K번 만큼 각 폴드 세트에 \n",
    "# 학습과 검증 평가를 반복. K가 5이면 5번 평가를 평균한 결과로 예측 성능 평가\n",
    "def exec_kfold(clf, folds):\n",
    "    kfold = KFold(n_splits=folds)\n",
    "    scores = []\n",
    "\n",
    "    for iter_count, (train_index, test_index) in enumerate(kfold.split(X_df)):\n",
    "        X_train, X_test = X_df.values[train_index], X_df.values[test_index]\n",
    "        y_train, y_test = y_df.values[train_index], y_df.values[test_index]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        scores.append(accuracy)\n",
    "        print('교차 검증 {0} 정확도: {1:.4f}'.format(iter_count, accuracy))\n",
    "#         print('검증 세트 인덱스: {1}'.format(iter_count, test_index))\n",
    "\n",
    "    mean_score = np.mean(scores)\n",
    "    print('평균 정확도: {0:.4f}'.format(mean_score))\n",
    "    \n",
    "exec_kfold(dt_clf, folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.6364\n",
      "교차 검증 1 정확도: 0.6667\n",
      "교차 검증 2 정확도: 0.7576\n",
      "교차 검증 3 정확도: 0.7727\n",
      "교차 검증 4 정확도: 0.8636\n",
      "교차 검증 5 정확도: 0.8182\n",
      "교차 검증 6 정확도: 0.8182\n",
      "교차 검증 7 정확도: 0.6515\n",
      "교차 검증 8 정확도: 0.7424\n",
      "교차 검증 9 정확도: 0.8462\n",
      "교차 검증 10 정확도: 0.8462\n",
      "교차 검증 11 정확도: 0.6462\n",
      "교차 검증 12 정확도: 0.8462\n",
      "교차 검증 13 정확도: 0.5077\n",
      "교차 검증 14 정확도: 0.6615\n",
      "교차 검증 15 정확도: 0.6154\n",
      "교차 검증 16 정확도: 0.6000\n",
      "교차 검증 17 정확도: 0.6769\n",
      "교차 검증 18 정확도: 0.8308\n",
      "교차 검증 19 정확도: 0.7231\n",
      "평균 정확도: 0.7264\n"
     ]
    }
   ],
   "source": [
    "# cross_val_scores\n",
    "# KFold의 일련의 과정을 한꺼번에 수행해주는 API\n",
    " \n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(dt_clf, X_df, y_df, cv=20)\n",
    "for iter_count, accuracy in enumerate(scores):\n",
    "    print('교차 검증 {0} 정확도: {1:.4f}'.format(iter_count, accuracy))\n",
    "\n",
    "print('평균 정확도: {0:.4f}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, error_score=nan,\n",
      "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
      "                                              criterion='gini', max_depth=None,\n",
      "                                              max_features=None,\n",
      "                                              max_leaf_nodes=None,\n",
      "                                              min_impurity_decrease=0.0,\n",
      "                                              min_impurity_split=None,\n",
      "                                              min_samples_leaf=1,\n",
      "                                              min_samples_split=2,\n",
      "                                              min_weight_fraction_leaf=0.0,\n",
      "                                              presort='deprecated',\n",
      "                                              random_state=0, splitter='best'),\n",
      "             iid='deprecated', n_jobs=None,\n",
      "             param_grid={'max_depth': [2, 3, 5, 10],\n",
      "                         'min_samples_leaf': [1, 5, 8],\n",
      "                         'min_samples_split': [2, 3, 5]},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring='accuracy', verbose=0)\n",
      "GridSearchCV 최적 하이퍼 파라미터: {'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "GridSeachCV 최고 정확도: 0.7994\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=5, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=0, splitter='best')\n",
      "dt 예측 정확도 : 0.7824427480916031\n",
      "오차 행렬\n",
      "[[142  14]\n",
      " [ 43  63]]\n",
      "\n",
      "정확도: 0.7824, 정밀도: 0.8182, 재현율: 0.5943,    F1: 0.6885\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV\n",
    "# DT 파라미터\n",
    "# max_depth : 트리의 최대 깊이\n",
    "# max_features : 최적의 분할을 위해 고려할 최대 피처 개수\n",
    "# max_leaf_nodes : 말단 노드의 최대 개수\n",
    "# min_samples_split : 노드를 분할하기 위한 최소한의 샘플 데이터. 디폴트 2. 작게 설정할 수록 분할되는 노드 증가, 과적합 가능성 증가\n",
    "# min_samples_leaf : 말단 노드가 되기 위한 최소한의 샘플 데이터 수\n",
    "# 교차 검증을 기반으로 하이퍼 파라미터의 최적 값을 찾게 해줌\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score , \\\n",
    "recall_score ,confusion_matrix, f1_score\n",
    "\n",
    "parameters = {'max_depth':[2,3,5,10], 'min_samples_split':[2,3,5],\\\n",
    "              'min_samples_leaf':[1,5,8]}\n",
    "\n",
    "grid_dclf = GridSearchCV(dt_clf, param_grid=parameters, scoring='accuracy', \\\n",
    "                         cv=5, refit=True)\n",
    "grid_dclf.fit(X_train, y_train)\n",
    "print(grid_dclf)\n",
    "# 교차검증을 기반으로 최적의 하이퍼 파라미터를 찾아줌\n",
    "print('GridSearchCV 최적 하이퍼 파라미터:', grid_dclf.best_params_)\n",
    "print('GridSeachCV 최고 정확도: {0:.4f}'.format(grid_dclf.best_score_))\n",
    "\n",
    "best_dclf = grid_dclf.best_estimator_\n",
    "print(best_dclf)\n",
    "dt_pred = best_dclf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, dt_pred)\n",
    "print('dt 예측 정확도 :', accuracy)\n",
    "\n",
    "get_clf_eval(y_test , dt_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한글 텍스트 처리 - 감성 분석(네이버 영화평점 150K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "news_df = pd.read_csv('./dataset/nsmc/ratings_train.txt', sep='\\t')\n",
    "news_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75173\n",
       "1    74827\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(150000,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = news_df.iloc[:,:-1]\n",
    "y = news_df.iloc[:,-1]\n",
    "print(X.shape)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X,y, test_size=0.2,random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 120000 entries, 94561 to 141209\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        120000 non-null  int64 \n",
      " 1   document  119996 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null, 숫자를 공백으로 처리\n",
    "import re\n",
    "X_train = X_train.fillna(' ')\n",
    "X_train.document = X_train.document.apply(lambda x : re.sub(r\"\\d+\",\" \",x))\n",
    "X_test = X_test.fillna(' ')\n",
    "X_test.document = X_test.document.apply( lambda x : re.sub(r\"\\d+\", \" \", x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.info())\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# morphs() 메서드는 입력 인자로 들어온 문장을 형태소 단어 형태로 토큰화해 \n",
    "# list 객체로 반환\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "def tw_tokenizer(text):\n",
    "    tokens_ko = okt.morphs(text)\n",
    "    return tokens_ko\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런의 TfidfVectorizor를 이용, TF-IDF 피처 모델을 생성(10분 소요)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# 위에서 만든 tw_tokenizer() 함수를 tokenizer로 사용. ngram_range는 (1,2) \n",
    "tfidf_vect = TfidfVectorizer(tokenizer=tw_tokenizer, ngram_range=(1,2),\\\n",
    "                             min_df=3, max_df=0.9) # 상위 10% 피처로 추출하지 않음\n",
    "tfidf_vect.fit(X_train.document)\n",
    "tfidf_train = tfidf_vect.transform(X_train.document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 3.5} 0.8555\n"
     ]
    }
   ],
   "source": [
    "# 교차검증 및 하이퍼파라미터 튜닝\n",
    "# Logistic Regression 을 이용하여 감성 분석 Classification 수행.\n",
    "# 로지스틱 회귀의 하이퍼 파라미터 C를 설정\n",
    "# C는 규제 강도를 조절하는 alpha 값의 역수로 작을 수록 규제 강도가 크며\n",
    "# Penalty는 규제의 유형을 설정하며 l1 규제와 ㅣ2 규제가 있으며 기본은 l2 임\n",
    "lr_clf = LogisticRegression(random_state=0)\n",
    "params = {'C': [1,3.5,4.5,5.5,10]}\n",
    "gcv_lr = GridSearchCV(lr_clf, param_grid=params, cv=3, scoring='accuracy',\\\n",
    "                      verbose=0)\n",
    "gcv_lr.fit(tfidf_train, y_train)\n",
    "print(gcv_lr.best_params_, round(gcv_lr.best_score_,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 정확도:  0.859\n"
     ]
    }
   ],
   "source": [
    "# 테스트 세트를 이용 예측시 학습할 때 적용한 TfidfVectorizer를\n",
    "# 그대로 사용해야 학습시 설정한 피처 개수와 테스트 데이터를 TfidfVectorizer로\n",
    "# 변경할 피처 개수가 같아짐\n",
    "from sklearn.metrics import accuracy_score\n",
    "tfidf_test = tfidf_vect.transform(X_test.document)\n",
    "best_estimator = gcv_lr.best_estimator_\n",
    "lr_preds = best_estimator.predict(tfidf_test)\n",
    "print('Logistic Regression 정확도: ',accuracy_score(y_test,lr_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 1 1 1]\n",
      "[0 0 1 0 0 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test.values[:10])\n",
    "print(lr_preds[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. RF, DT를 이용하여 네이버 영화평점 감성 분석 Calssification을 수행하세요.\n",
    "- GridSearchCV를 이용 교차검증(cv=3)과 하이퍼파라미터 튜닝 \n",
    " - RF params = {'n_estimators':[50,100, 200], 'max_depth':[2,3,5], 'min_samples_leaf':[1,5,8]}\n",
    " - DT params = {'max_depth':[2,3,5,10], 'min_samples_split':[2,3,5],'min_samples_leaf':[1,5,8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  81 out of  81 | elapsed:  4.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_samples_leaf': 5, 'n_estimators': 200} 0.7538\n",
      "rf 정확도: 0.7545\n"
     ]
    }
   ],
   "source": [
    "# rf을 이용하여 감성 분석 Classification 수행\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "params = {'n_estimators':[50,100, 200], 'max_depth':[2,3,5], 'min_samples_leaf':[1,5,8]}\n",
    "gcv_rf = GridSearchCV(rf_clf, param_grid = params, cv=3, scoring= 'accuracy',verbose=1)\n",
    "gcv_rf.fit(tfidf_train, y_train)\n",
    "print(gcv_rf.best_params_, round(gcv_rf.best_score_,4))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "tfidf_test = tfidf_vect.transform(X_test.document)\n",
    "best_estimator = gcv_rf.best_estimator_\n",
    "rf_preds = best_estimator.predict(tfidf_test)\n",
    "print('rf 정확도:', accuracy_score(y_test,rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt를 이용하여 감성 분석 Classification 수행\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "params = {'max_depth':[2,3,5,10], 'min_samples_split':[2,3,5],\\\n",
    "              'min_samples_leaf':[1,5,8]}\n",
    "gcv_dt = GridSearchCV(dt_clf,param_grid = params, cv=3, scoring='accuracy',verbose=0)\n",
    "gcv_dt.fit(tfidf_train, y_train)\n",
    "print(gcv_dt.best_params_, round(gcv_dt.best_score_,4))\n",
    "\n",
    "tfidf_test = tfidf_vect.transform(X_test.document)\n",
    "best_estimator = gcv_dt.best_estimator_\n",
    "dt_preds = best_estimator.predict(tfidf_test)\n",
    "print('dt 정확도:', accuracy_score(y_test,dt_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip\n",
    "# SVM를 이용하여 감성 분석 Classification 수행\n",
    "# 벡터 공간으로 매핑하는 함수를 커널이라고 함. \n",
    "# kernel='rbf'옵션으로 RBF(Radial Basis Function) 함수를 적용\n",
    "\n",
    "from sklearn import svm \n",
    "from sklearn.metrics import accuracy_score\n",
    "svm_clf = svm.SVC(kernel='rbf', random_state=0)\n",
    "params = {\"C\": [1, 10, 100, 1000], \"kernel\":[\"rbf\"], \"gamma\":[0.001, 0.0001]}\n",
    "\n",
    "#[     {\"C\": [1, 10, 100, 1000], \"kernel\":[\"linear\"]},   \n",
    "#     {\"C\": [1, 10, 100, 1000], \"kernel\":[\"sigmoid\"], \"gamma\": [0.001, 0.0001]}]\n",
    "\n",
    "\n",
    "svm_clf = GridSearchCV( svm_clf, param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
    "svm_clf.fit(tfidf_train, y_train)\n",
    "print(svm_clf.best_params_, round(svm_clf.best_score_,4))\n",
    "\n",
    "tfidf_test = tfidf_vect.transform(X_test.document)\n",
    "svm_best_estimator = svm_clf.best_estimator_\n",
    "svm_preds = svm_best_estimator(tfidf_test)\n",
    "\n",
    "print(\"svm 정확도 : \" , accuracy_score(y_test, svm_preds))\n",
    "# The class sklearn.svm.SVC has parameter max_iter=-1 by default. \n",
    "# This causes the optimizer to have no maximum number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip\n",
    "# KNN\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(knn_clf, tfidf_train, y_train, cv=5)\n",
    "for iter_count, accuracy in enumerate(scores):\n",
    "    print('교차 검증 {0} 정확도: {1:.4f}'.format(iter_count, accuracy))\n",
    "\n",
    "print('평균 정확도: {0:.4f}'.format(np.mean(scores)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
