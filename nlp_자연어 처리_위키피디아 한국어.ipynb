{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위키피디아 한국어 Corpus에 Word2Vec 알고리즘 적용한 wiki.model 생성 및 이를 활용한 유사어 조사 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작업시간 유의(코퍼스 생성하기, wiki.txt, wiki.wakati 파일 복사 활용)\n",
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "from konlpy.tag import Okt\n",
    "from gensim.models import word2vec\n",
    "# 파일 열기\n",
    "readFp = codecs.open(\"./dataset/wiki.txt\", \"r\", encoding=\"utf-8\")\n",
    "wakati_file = \"wiki.wakati\"\n",
    "writeFp = open(wakati_file, \"w\", encoding=\"utf-8\")\n",
    "\n",
    "# 형태소 분석 \n",
    "okt = Okt()\n",
    "i = 0\n",
    "# 텍스트를 한 줄씩 처리하기\n",
    "while True:\n",
    "    line = readFp.readline()\n",
    "    if not line: break\n",
    "    if i % 20000 == 0:\n",
    "        print(\"current - \" + str(i))\n",
    "    i += 1\n",
    "    # 형태소 분석\n",
    "    malist = okt.pos(line, norm=True, stem=True)\n",
    "    # 필요한 어구만 대상으로 하기\n",
    "    r = []\n",
    "    for word in malist:\n",
    "        # 어미/조사/구두점 등은 대상에서 제외 \n",
    "        if not word[1] in [\"Josa\", \"Eomi\", \"Punctuation\"]:\n",
    "            writeFp.write(word[0] + \" \")\n",
    "writeFp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작업시간 유의(Word2Vec skip-gram 알고리즘을 사용한 모델 생성 및 저장)\n",
    "from gensim.models import word2vec\n",
    "# 띄어쓰기로 구분된 파일을 읽어 들여 코퍼스로 사용할 수 있게 분할\n",
    "data = word2vec.Text8Corpus(\"./dataset/wiki.wakati\")\n",
    "# 모델을 생성\n",
    "# 매개변수 : sg 알고리즘 선택(1=Skip-gram, 0=CBOW), size 벡터의 차원 설정, \n",
    "# window 학습할 단어를 연관시킬 앞뒤의 단어 수\n",
    "model = word2vec.Word2Vec(data, sg=1, size=100, window=5)\n",
    "# 생성한 모델을 파일로 저장\n",
    "model.save(\"./dataset/wiki.model\")\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim 설치 : 자연 언어 처리를 위한 라이브러리로 Word2Vec 기능 포함\n",
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "model = word2vec.Word2Vec.load('./dataset/wiki.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[('전산언어학', 0.7927480936050415), ('객체지향', 0.774531364440918), ('자연언어', 0.7666630744934082), ('말뭉치', 0.7620400786399841), ('UML', 0.7490293383598328), ('통사론', 0.7273504734039307), ('전문용어', 0.7267319560050964), ('전산학', 0.7123903036117554), ('휴리스틱', 0.7028846740722656), ('기계번역', 0.6998603940010071)]\n"
     ]
    }
   ],
   "source": [
    "# 위키피디아 모델 파일 활용, 유사어 조사\n",
    "md1 = model.wv.most_similar(positive=['NLP','자연어'])\n",
    "print(len(md1))\n",
    "print(md1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('엄마', 0.8511905074119568)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# '아빠 - 남성 + 여성' 계산\n",
    "model.wv.most_similar(positive=['아빠','여성'], negative=['남성'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('왕녀', 0.7457159757614136),\n",
       " ('여왕', 0.6352607011795044),\n",
       " ('왕', 0.619939923286438),\n",
       " ('대왕', 0.5986748933792114),\n",
       " ('삼촌', 0.5951403379440308),\n",
       " ('왕세자', 0.5889936685562134),\n",
       " ('왕비', 0.5851935744285583),\n",
       " ('갈라드리엘', 0.5823298096656799),\n",
       " ('공주', 0.5798119902610779),\n",
       " ('아들', 0.5790980458259583)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# '왕자 - 남성 + 여성'\n",
    "model.wv.most_similar(positive=['왕자','여성'],negative=['남성'])[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('도쿄', 0.676599383354187),\n",
       " ('오사카', 0.6547168493270874),\n",
       " ('교토', 0.6285207867622375),\n",
       " ('서울특별시', 0.5485527515411377),\n",
       " ('후쿠오카', 0.5434316992759705)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 한국에서 서울에 해당하는 곳은 일본에서 어디인가요? '서울 - 한국 + 일본'\n",
    "model.wv.most_similar(positive=['서울','일본'],negative=['한국'])[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('베이징', 0.6575207114219666),\n",
       " ('북경', 0.6304327845573425),\n",
       " ('봉천', 0.6280224323272705),\n",
       " ('항주', 0.6195797920227051),\n",
       " ('남경', 0.6111494302749634)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중국의 수도\n",
    "model.wv.most_similar(positive=['서울','중국'],negative=['한국'])[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('여자', 0.780625581741333)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 오른쪽과 왼쪽이라는 반대되는 개념을 넣고 한쪽에 남자를 넣으면?\n",
    "model.wv.most_similar(positive=['오른쪽','남자'],negative=['왼쪽'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('강남', 0.6651614904403687),\n",
       " ('여의도', 0.6196600794792175),\n",
       " ('인사동', 0.6163415908813477),\n",
       " ('연희동', 0.6118510365486145),\n",
       " ('서울특별시', 0.6044690012931824)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 서울에서 맛집으로 유명한 지역은 어디일까요?\n",
    "model.wv.most_similar(positive=['서울','맛집'])[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0280149  -0.5838621  -0.4873174  -0.21167026 -1.8950337 ]\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# 벡터데이터 확인 : 100차원 벡터 데이터(size = 100)\n",
    "print((model.wv['고양이'])[0:5])\n",
    "print(len(model.wv['고양이']))\n",
    "print(len(model.wv['강아지']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('케이크', 0.8118672370910645)\n",
      "('주먹밥', 0.8109839558601379)\n",
      "('디저트', 0.8098270297050476)\n",
      "('튀김', 0.8025590181350708)\n",
      "('김밥', 0.7943276762962341)\n",
      "('돈가스', 0.7917213439941406)\n",
      "('비스킷', 0.7907963991165161)\n",
      "('야채', 0.7853391170501709)\n",
      "('닭고기', 0.7846125960350037)\n",
      "('조미료', 0.7839272618293762)\n"
     ]
    }
   ],
   "source": [
    "# 모델을 사용해 계산하기 - 유의어\n",
    "from gensim.models import word2vec\n",
    "model = word2vec.Word2Vec.load(\"./dataset/wiki.model\")\n",
    "results = model.wv.most_similar(positive=['과자'])\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컴퓨터에 갑자기 문제가 생겼어요. 빨리 처리할 문제가 있어서 해결 요청합니다.\n",
      "- 컴퓨터 : -0.07506699\n",
      "- 갑자기 : 0.5643145\n",
      "- 문제 : 0.25628287\n",
      "- 생기다 : 0.2879802\n",
      "- 빨리 : 0.5591332\n",
      "- 처리 : 0.18828717\n",
      "- 하다 : 0.42797402\n",
      "- 문제 : 0.25628287\n",
      "- 있다 : 0.31476456\n",
      "- 해결 : 0.19012733\n",
      "- 요청 : 0.35598242\n",
      "- 하다 : 0.42797402\n",
      "사용 방법을 문의 드립니다.\n",
      "- 사용 : -0.048614163\n",
      "- 방법 : 0.25084788\n",
      "- 문의 : 0.27857858\n",
      "- 드리다 : 0.25129128\n"
     ]
    }
   ],
   "source": [
    "# 지원 센터에서 업무 개선을 위해 메일과 채팅으로 접수된 문장이 \n",
    "# 급한 내용일 경우 우선도를 올려 대응해야 하는 경우\n",
    "# 메일에 포함된 문장을 형태소 분석하고 Word2Vec로 '급하다'와\n",
    "# 유사도가 어느 정도인지 확인하는 방법으로 변경\n",
    "from konlpy.tag import Okt\n",
    "from gensim.models import word2vec\n",
    "# Word2Vec 모델 읽어 들이고 형태소 분석 준비하기\n",
    "model = word2vec.Word2Vec.load(\"./dataset/wiki.model\") \n",
    "okt = Okt()\n",
    "def print_emargency(text):\n",
    "    print(text)\n",
    "    # 전달된 문장을 형태소 분석하기\n",
    "    node = okt.pos(text, norm=True, stem=True)\n",
    "    for word, form in node:    \n",
    "    # 필요한 형태소만 추출하기\n",
    "        if form == 'Noun' or form == 'Verb' or form == 'Adjective' or form == 'Adverb':            \n",
    "      # 급하다와 비슷한 단어\n",
    "            print(\"-\", word, \":\", model.wv.similarity(word, '급하다'))\n",
    "# 첫 문장은 갑자기 빨리, 요청 등 전체적으로 높은 값이 나온 반면 두번째 문장은 비교적 낮은 값이 나옴\n",
    "print_emargency(\"컴퓨터에 갑자기 문제가 생겼어요. 빨리 처리할 문제가 있어서 해결 요청합니다.\")\n",
    "print_emargency(\"사용 방법을 문의 드립니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
