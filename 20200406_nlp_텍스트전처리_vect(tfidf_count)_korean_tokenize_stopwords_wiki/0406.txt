<수업에 들어가기 전에>

scala vs vector
: 스칼라는 값만 가지고 있는 형태, 벡터는 방향성도 가지고 있음

희소행렬

*
NLP
기계가 자연어를 이해하는 방법
전처리 the, cat, sat, on, the, hat
피처 벡터화 - 원핫인코딩 사전작업
cat [0, 1, 0, 0, 0, 0]
the [1, 0, 0, 0, 0] ?

말뭉치 사전
단어를 사전을 사용하여 매핑, 이를 벡터로 변환
벡터화하여 숫자로 표현하면 분류나 회귀 등의 다양한 분석이 가능

- 정확한 벡터화를 위하여 뭐가 필요한가
가이드가 될 수 있는 것, 말뭉치 사전
데이터 분석에서 가장 중요한 것은 데이터
자연어 처리에서 가장 중요한 것은 말뭉치 사전
말뭉치 사전이 크면 클수록 좋다 - 더 많은 학습이 가능하므로, 정확도도 높아지고

자연어 처리를 위한 데이터 셋 만드는 것
MNIST이라는 데이터셋
분석에 맞는 데이터셋을 만들어주는 영역
굉장한 수요
기능적인 사람은 제한적

<자연어 관련 용어>

말뭉치 corpus
: 텍스트 문서의 집합

Token
: 뜻을 가지는 최소한의 단위, 단어처럼 의미를 가지는 요소

형태소 Morphemes
: 의미를 가지는 언어 요소에서 최소 단위
- 의미를 살릴 수 있는 최소 단위, 더 분석하면 뜻이 없어지는 말의 단위

품사 POS

불용어 Stopword
: 조사, 접사와 같이 자주 나타나지만 실제 의미에 기여하지 못하는 단어(문법적, 의존적)

어간 추출 Stemming
: 어간만 추출하는 것을 의미(running, runs, run -> run)

음소표기법 Lemmatization
: 앞뒤 문맥을 보고 단어를 식별하는 것

<NLP-텍스트 벡터화>
* one-hot encoding
단어를 벡터로 바꾸는 가장 단순한 방법으로 단어에 번호를 매기고 그 번호에 해당하는 요소만 1로 할당하고 나머지는 0을 갖는 벡터로 변경

N개의 단어가 있다면 각 단어는 한 개의 요소만 1인 N차원의 벡터로 표현
단점은 벡터 표현에 단어와 단어 간의 관계가 전혀 드러나지 않는다는 점

* word embedding(dense representation, distributed representation)
단어를 벡터로 바꿀 때 의미도 담을 수 있게 한다면
비슷한 의미의 단어들은 비슷한 벡터로 표현할 수 있다면
단어와 단어 간의 관계를 벡터를 통해서 드러날 수 있게 한다면

각각의 속성을 독립적인 차원으로 표현하지 않고 우리가 정한 개수의 차원으로 대상을 대응시켜서 표현

* Dense representation의 장점
적은 차원으로 대상을 표현하여 차원이 높을 시 차원의 저주(curse of dimensionality) 문제 발생
- 의미 없는 칼럼값을 붙일 시 정확도가 떨어짐(오히려 분석에 방해요소가 되는), 그래서 데이터 전처리 때 필요없는 값들은 제거함
더 큰 일반화 능력(generalize power)
강아지와 멍멍이(one-hot encoding에서 둘은 다른 단어로 표현되지만 word embedding에서는 굉장히 유사한 벡터로 표현됨)

타이타닉의 생존자를 예측하는 데 필요하지 않은 데이터
embarked 지운 이유

predictive method란 지도학습을 통하여 맥락으로 단어를 예측하거나 단어로 맥락을 예측
단어를 어떻게 표현할지를 배움, 어떻게 벡터로 표현하는지도

<자연어 처리 python 라이브러리>
1. NLTK
- 파이썬의 대표적인 자연어 처리 라이브러리
- 방대한 데이터셋과 서브모듈을 가지고 있으며 NLP의 거의 모든 영역을 커버

2. KoNLPy
- 우리나라 한글에 특화된 자연어 처리 라이브러리
- 단어 품사별로 분류 (hannanum, kkma(코쿠마), okt(트위터), komoran, mecab)
- okt가 가장 많이 쓰임

3. Gensim
- 문서 사이의 유사도를 계산, 텍스트 분석을 돕는 라이브러리(Word Embedding의 Word2Vec 방식 제공)
- 토픽 모델링(Topic Modelling) 분야에서 가장 두각(그러나 대부분의 자연어 처리에서 사용됨)
- Word Embedding: word2Vec

4. Spacy

5. Scikit-learn
feature-extraction
DicVectorizer
CountVectorizer
TfidfVectorizer
HashingVectorizer

* NLP 시장
기계번역, 정보추출, 자동 요약, 질문 답변, 텍스트 분류, 감정 분석 및 기타(스팸 인식 및 언어 감지 등) 분류

지원 및 유지 보수와 같은 새로운 서비스의 필요성도 증가
기반이 되는 텍스트를 컴퓨터가 읽을 수 있는 형태로 모어놓은 언어 자료 '말뭉치(말모둠, 글모둠)'양이 클수록 AI가 인식할 수 있는 자연어의 정확도가 높아지면 AI가 얼마나 학습하느냐에 그 성능이 좌우

"""
실행 전 가상환경 만들기
"""
anaconda prompt를 관리자 권한으로 실행(cmd 창 팝업)
"""
(base) C:\windows\system32>conda env list
# conda environments:
#
base                  *  C:\ProgramData\Anaconda3
tensorflow2              C:\Users\admin\.conda\envs\tensorflow2


(base) C:\windows\system32>conda create -n nlp_python python=3.7
Collecting package metadata (current_repodata.json): done
Solving environment: done


==> WARNING: A newer version of conda exists. <==
  current version: 4.7.12
  latest version: 4.8.3

Please update conda by running

    $ conda update -n base -c defaults conda



## Package Plan ##

  environment location: C:\ProgramData\Anaconda3\envs\nlp_python

  added / updated specs:
    - python=3.7


The following packages will be downloaded:

    package                    |            build
    ---------------------------|-----------------
    certifi-2019.11.28         |           py37_1         157 KB
    openssl-1.1.1f             |       he774522_0         4.8 MB
    pip-20.0.2                 |           py37_1         1.7 MB
    python-3.7.7               |h60c2a47_0_cpython        14.8 MB
    setuptools-46.1.3          |           py37_0         528 KB
    wheel-0.34.2               |           py37_0          66 KB
    ------------------------------------------------------------
                                           Total:        22.0 MB

The following NEW packages will be INSTALLED:

  ca-certificates    pkgs/main/win-64::ca-certificates-2020.1.1-0
  certifi            pkgs/main/win-64::certifi-2019.11.28-py37_1
  openssl            pkgs/main/win-64::openssl-1.1.1f-he774522_0
  pip                pkgs/main/win-64::pip-20.0.2-py37_1
  python             pkgs/main/win-64::python-3.7.7-h60c2a47_0_cpython
  setuptools         pkgs/main/win-64::setuptools-46.1.3-py37_0
  sqlite             pkgs/main/win-64::sqlite-3.31.1-he774522_0
  vc                 pkgs/main/win-64::vc-14.1-h0510ff6_4
  vs2015_runtime     pkgs/main/win-64::vs2015_runtime-14.16.27012-hf0eaf9b_1
  wheel              pkgs/main/win-64::wheel-0.34.2-py37_0
  wincertstore       pkgs/main/win-64::wincertstore-0.2-py37_0


Proceed ([y]/n)? y


Downloading and Extracting Packages
setuptools-46.1.3    | 528 KB    | ############################################################################ | 100%
python-3.7.7         | 14.8 MB   | ############################################################################ | 100%
pip-20.0.2           | 1.7 MB    | ############################################################################ | 100%
wheel-0.34.2         | 66 KB     | ############################################################################ | 100%
openssl-1.1.1f       | 4.8 MB    | ############################################################################ | 100%
certifi-2019.11.28   | 157 KB    | ############################################################################ | 100%
Preparing transaction: done
Verifying transaction: done
Executing transaction: done
#
# To activate this environment, use
#
#     $ conda activate nlp_python
#
# To deactivate an active environment, use
#
#     $ conda deactivate


(base) C:\windows\system32>conda env list
# conda environments:
#
base                  *  C:\ProgramData\Anaconda3
nlp_python               C:\ProgramData\Anaconda3\envs\nlp_python
tensorflow2              C:\Users\admin\.conda\envs\tensorflow2


(base) C:\windows\system32>
"""

"""
주피터 노트북 실행 환경 만들기
"""
"""
activate nlp_python
conda install jupyter notebook
"""

"""
패키지 설치하기
"""
conda install numpy pandas matplotlib seaborn scikit-learn tensorflow keras
"""

맥락으로 단어를 예측하는 CBOW(continuous bag of words)모델